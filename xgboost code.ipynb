{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mujaVlHHetaM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.models import Sequential                                             "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmFsyiqLe9DJ",
        "outputId": "d5f54ee8-442d-4c3a-eb56-0956be818ee8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 6s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# loading the dataset \n",
        "from tensorflow.keras import datasets\n",
        "(train_img, train_lab), (test_img, test_lab) = datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "5pIOQqQ9fWqn",
        "outputId": "f7e777b1-0528-4c0b-85ab-25bfff83e743"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdc7c614160>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAv2ElEQVR4nO3df3TU9Z3v8dfMZGbye0II+SVBAQVUfvSWKmZtWSusQPd6tHJbbXtP0Xr16EbPKtvdlj2tVnf3xLXntLY9iGfPunJ6TtHWvUWv3q1WsYTbFthKYfFnBIwShIQfkkxIMpP58b1/uOTeKMLnDQmfJD4f58w5kHnnnc93vt+Z93wzM6+EgiAIBADAWRb2vQAAwCcTAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4EWB7wV8WD6f1/79+1VWVqZQKOR7OQAAoyAI1NPTo/r6eoXDH3+eM+oG0P79+9XQ0OB7GQCAM9Te3q7Jkyd/7PUjNoBWr16t73//++ro6NC8efP0k5/8RJdeeukpv6+srEyStPCi81QQcfsNYcaxTpLCeedSSVJBzv0booUxU+9ZF1/kXFtYUmzqfaQv7Vy7+939pt7T6+pM9bU1E51rM7LtoEzgvu/3tb9n6j2hpMy9NlFu6l0YMZWbflmeTGVNrbtT7sdKsqvH1Lu355hz7bHepKl3XX2Nc21RzHb/6Th01FSfjbjf91N9A6beB/d1OteGCmz3n9Iy92M8Ei1yrs1ls9q2bdPg4/nHGZEB9POf/1wrV67UI488ogULFuihhx7SkiVL1Nraqurq6pN+7/FfuxVEws4DKIi435vDxt/qWW6gaIHtUSUeizrXFsZtwy2WdT8QCwpsh0HMsG5JKozHnWvDypl6hwP32zwWta07FnO/zeOGbZSkwogxgtFw4KYNQ1mSYnn3tUSNt2HUcGyZj0PDWqzHbLTAVh8y1GcLbPs+EnY/xkMR2wNcJDJy+0fSKV9GGZE3IfzgBz/QLbfcoptuukkXXXSRHnnkERUXF+tf/uVfRuLHAQDGoGEfQAMDA9q2bZsWL178/35IOKzFixdr8+bNH6lPp9NKJpNDLgCA8W/YB9Dhw4eVy+VUUzP097M1NTXq6Oj4SH1zc7MSicTghTcgAMAng/fPAa1atUrd3d2Dl/b2dt9LAgCcBcP+JoSqqipFIhF1dg5950ZnZ6dqa2s/Uh+Px80v4AIAxr5hPwOKxWKaP3++NmzYMPi1fD6vDRs2qLGxcbh/HABgjBqRt2GvXLlSK1as0Gc+8xldeumleuihh9Tb26ubbrppJH4cAGAMGpEBdP311+vQoUO655571NHRoU996lN67rnnPvLGBADAJ1coCALjJ+JGVjKZVCKR0KK505w/iJoP3OdoLjB+IC3v/sHIopjtg6gXzZ3jvo5C2+tk6QL3+oLyKlPvcya6JxtI0vTp5znXxsttn1gvKi11ro0ZPnQnSTKkYPR0dZtaGz/PqVSq37m2vf2Aqfeu3W8712794zZT72ze/TYMAtuHKBMV7sdhqM/99pOkfW/tNtXHDcdhqteWhJDr7XOuLYjaPshdlqhwro0bkkEy2axe2LZF3d3dKi//+JQQ7++CAwB8MjGAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXoxIFtxwyIVO/ffEjyvKu0fgDAS2SJt8yD1KJJexxWD097nXV9fZcvSqzp3mXHvexXNNvSdPsq2lIOaeO5OJ2JKhwlH3+JYi45/9iEfc153qc49LkaS39rTa6vfuca59r+1dU+/33t3nXJseSJt6Tzyn3rk2Giky9Y7F3aNh+vtt8UT55DFTfS7rfl+OpLOm3rH+lHNtecT2GFQccn/sjGTc153Jua2DMyAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAF6M2Cy4bjklht5yiWNqQH5a3ZY0lC9xn9MWzZ5t6z7vkM861iYmVpt4qLHQubX/vPVPrdK8tD6xvIONc+1Z7m6l3rMg9y6q0qNjUe8b0851rs+kBU++f/8//Zarf8cdtzrXRvHt+oSTlU+77Mx+3PWd9/+j7zrVFhe7ZbpKUOdrjXNvX0WHr7Zhldlxh2D2TMCTb/lG637m0osj9fi9JGUPm3dEj7vsyG7g9znIGBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwYtRG8Uy7aK5isZhTbdemzc59k0e6TOuY+YUlzrV//pUbTL13v73Hufa9ve2m3jnDU4uBAVuMTPjCOab6A0eOOtdu2b7d1HvipArn2sJo1NR799vvONfOumCGqXehMXbGUp9N9Zl692bc41hiUbf75HGZlPuxFWS6TL17+9wjao4e6TT1Li217Z+gqMi5tq/X/faWpHBgiAUqKTH1TqXdY5h6clnnWqJ4AACjGgMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAODFqM2Cmzd/gYoc85Ve/Y83nftOKJpoWseKW/+Hc2374UOm3n98q9W5NlbsnjUlSRUV7llWsbjteciEiRWm+r2HDzvXRuK2rLHi0nLn2miB7XB/5133/L1Q2JYzN2fOPFN9f6977tkrr9jy9LoN2XFFllwySZWOeY6SFORsmYRF8bxzbWFDjal3YUGFqb6z4z3n2uSAe/6aJJXE3Y+t9+R+m0hSfyziXNsVdt+XuXxecoi84wwIAODFsA+g733vewqFQkMus2bNGu4fAwAY40bkV3AXX3yxXnzxxf/3Q4y/+gAAjH8jMhkKCgpUW1s7Eq0BAOPEiLwGtGvXLtXX12vatGn62te+pr17935sbTqdVjKZHHIBAIx/wz6AFixYoLVr1+q5557TmjVr1NbWps997nPq6ek5YX1zc7MSicTgpaGhYbiXBAAYhYZ9AC1btkxf+tKXNHfuXC1ZskT/9m//pq6uLv3iF784Yf2qVavU3d09eGlvt/3paQDA2DTi7w6oqKjQjBkztHv37hNeH4/HFY/HR3oZAIBRZsQ/B3Ts2DHt2bNHdXV1I/2jAABjyLAPoG9+85tqaWnRO++8o9///vf64he/qEgkoq985SvD/aMAAGPYsP8Kbt++ffrKV76iI0eOaNKkSfrsZz+rLVu2aNKkSaY+r27eoljULYLiaMo92uLPv/Rl0zoqat2je3769C9NvVO5jHNt1pbeoewh92+IZLOm3pkB93VLUkf7u861yf37Tb0TUfdDOBuz/ao3FYSca1vbPv6dnidSXWX7mMKFc+Y613b3nvgNPx+n48hB59q+rG3fxw2xM4ZdKckW3VMQtkVZHep631bf3e1cmzEcV5I0EHY/T+hJp0y9ZfiMZibsHtuTl9s2DvsAeuKJJ4a7JQBgHCILDgDgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgxYj/OYbT1fLrFxUJueUJferC2c59L716qWkdv3rh1861O7dvN/XOGjLYUilbxlM+k3OurSgpNfVe/Pk/M9W/3fqWc+32zZtNvbO9fc61E6dNM/UOG3KyIsqbere++Yap/k8aL3OubZgyxdQ7m3c/Dl997T9svQ2xZ/GoLasv4pgVKUmhnO25djJpy4Krrq5xri0uLjb13m/IR+zt7TX1zqfds/0yGffaIAic6jgDAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4MWqjeP7b11YoHneL5lh42Z+4N47aYjB+1/I759rD7x0w9c7m3ONyUv39pt4DAwPOtbEGW3SLa8zGcf2Gtff22bbz9TfedK4tOdRh6l1T7x6vUldZZerdlTxqqt/zmvtxO7XhHFPvQO77Mz1g2z/vvrPbuXYg7X7MSlIu7R5PlepLm3pPM8Y23X77XzjXzpo1y9T73Xffda7du3evqfeBA+6PWW1tbzvXDgwM6Imf/+yUdZwBAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALwYtVlwTd/8a5WXlTvVJo+452ptf/M10zpef+0N59r+7h5T73w+71ybzWRNvXM593prtlsoFDLVj6T+tHvGV/e7e0y9uw/uc64NTZ9h6h0NbLfhoQP7nWuv//rXTb1Litxz5i6ccaGp95HOTufat3e55/pJUrzA/fnzZZc2mnp/46bbTPWf/vSnnWut97eqKvecwU996lOm3jlDHqUlX7Knp4csOADA6MUAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4MWqz4AZyOaUdc4pyBe6bUVBYZFrH/P8y37k2nMmYencnk861XUe7TL0zgXvGU6y40NS7q8u2llg06lxbVOyeSyZJYUPvSChi6p0zZF+9vafd1DuTdu8tSQWG7dz8+y2m3gs//3nn2q1/+HdT75LCEufaC2dcZOp9eeMlzrX/bfmXTb3PO+8CU70lU81SK0nhsPt5gqVWkmKxmHNtYaH744RrXCRnQAAAL8wDaNOmTbr66qtVX1+vUCikp556asj1QRDonnvuUV1dnYqKirR48WLt2rVruNYLABgnzAOot7dX8+bN0+rVq094/YMPPqgf//jHeuSRR7R161aVlJRoyZIlSqVSZ7xYAMD4YX4NaNmyZVq2bNkJrwuCQA899JC+853v6JprrpEk/fSnP1VNTY2eeuop3XDDDWe2WgDAuDGsrwG1tbWpo6NDixcvHvxaIpHQggULtHnz5hN+TzqdVjKZHHIBAIx/wzqAOjo6JEk1NTVDvl5TUzN43Yc1NzcrkUgMXhoaGoZzSQCAUcr7u+BWrVql7u7uwUt7u+3trACAsWlYB1Btba0kqfNDfwe+s7Nz8LoPi8fjKi8vH3IBAIx/wzqApk6dqtraWm3YsGHwa8lkUlu3blVjY+Nw/igAwBhnfhfcsWPHtHv37sH/t7W1aceOHaqsrNSUKVN011136e///u91wQUXaOrUqfrud7+r+vp6XXvttcO5bgDAGBcKgiCwfMPGjRv1+RNEd6xYsUJr165VEAS699579U//9E/q6urSZz/7WT388MOaMWOGU/9kMqlEIqGNm7aqtLTU6XuKitzjdTLGuJz3D3aeuug/lRnWIUm9vX3Otclkt6l34JqFIanz8CFT7+rqalP9O21tzrW79rxt6h2KuG9n/zHbdh7t6nWufWffMVPvjs7Dpvpsxv1YqZ40wdT7b1d907k2bYgnkqTubvfjdu7FF5p6z7l4lnNtSYnbY8lx2Zz7cTXiDA/RedvDuSwP/5baZDKp86ZOVnd390lfVjGfAV1xxRUnXUgoFNL999+v+++/39oaAPAJ4v1dcACATyYGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAtzFM/ZcvT9QxpIu+VfRQrcN+PIYVsG1xuvve5ce+WVH83IO5nK6onOtROrK029LbfJ9Bnnm3pnszlT/TnnnONcu/AEOYMnE4tFnGsz6R5T7wOH+p1rn3npP0y93zNmwbW17nSu/ZP5tky1KZMnO9da9qUkhSPux2Flhe1PsYSVd67N52wZaaGQ7bl5yJC9aIzflAy9w9beI6TA8fGHMyAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBejNoonne5TxDFlJRx2n6Pp/l7TOoLAPe7j8KEOU+++7v3Ote8ffMfUO1ZU7FybqD7P1PvdvQdN9b/fss25duHnF5p6z73IPXYmErXFyLTtfdO5NtlnuytFSmpM9RdcONe59r9/5VpT78nnVDnXhl3vlP8pWuBen0q7Rx9JUljusTOhsG3dhoeUD/pb4nKMzS29RwvXNXMGBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPBi1GbBdXcd1UA65VQbi8Wc+5aVl5rWMWPmTOfaIJ8x9X6/413n2r27/mDqXVhc6FybHegx9Y7li0z1NQn3wyx1tN3U+/1O98y797sOm3r/2/9+0bk2UxA39T7Y22eq/9KSzzjXFgRpU+8DHe8510aM2xmPumewxWK23gWGnLlogftjxAe9rWtxP8atWXAj2XukcubyebcMTc6AAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABejNoontWrVysScYvaSKfdo0e+/OUvm9YxZcpU59ps2hbF8/Zbu5xrD7W7x6VIUlWFe/RIz6EDpt6lxRNN9TMrJjjXFmf2mnoffafXuXbfIVv8TXnc/TZPBZWm3lOrE6b6GVOqnWt7uo6YeucNUVahsO02LFBg6G17Puz6+CBJkbDtoc4axRONRt3XYlj3B2txX3s8blt3UZF7rJZlHamUW4waZ0AAAC8YQAAAL8wDaNOmTbr66qtVX1+vUCikp556asj1N954o0Kh0JDL0qVLh2u9AIBxwjyAent7NW/ePK1evfpja5YuXaoDBw4MXh5//PEzWiQAYPwxvwlh2bJlWrZs2Ulr4vG4amtrT3tRAIDxb0ReA9q4caOqq6s1c+ZM3X777Tpy5OPflZNOp5VMJodcAADj37APoKVLl+qnP/2pNmzYoH/8x39US0uLli1bplwud8L65uZmJRKJwUtDQ8NwLwkAMAoN++eAbrjhhsF/z5kzR3PnztX06dO1ceNGLVq06CP1q1at0sqVKwf/n0wmGUIA8Akw4m/DnjZtmqqqqrR79+4TXh+Px1VeXj7kAgAY/0Z8AO3bt09HjhxRXV3dSP8oAMAYYv4V3LFjx4aczbS1tWnHjh2qrKxUZWWl7rvvPi1fvly1tbXas2eP/uZv/kbnn3++lixZMqwLBwCMbaEgCNzDmvTBO9w+//nPf+TrK1as0Jo1a3Tttddq+/bt6urqUn19va666ir93d/9nWpqapz6J5NJJRIJlZaWKhQKOX2Pa+6QJE2ZMsW5VpJuuukbzrV11bY8sLde2epc29neaupdEnXPx4vm+029YyH37DBJioez7rVx23OiPhW6F5fa1p0KuWfY1U5eaOpdM3mGqT5R5H43jUXcb29JGihwv10Cud0njwsHJ37z0YlYM9IiEcsvcGy9Q8Z6S06apVYa2Zy5sCF/z7KOY8eO6XMLG9Xd3X3Sl1XMZ0BXXHGFTjaznn/+eWtLAMAnEFlwAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvhv3vAQ2XwsJC55yioqIi574HDx40raNl42+ca//rF64y9Z5UXe9cW1ocN/Ue6D/qXNvf22XqHXKP95IkpTM9zrW9qWOm3tFi9xyzsPKm3hG55+lNLLdlcBWGek31A/0Z59psge15ZSbivkMzGVvOXNSwlGjMltVnY7tNwiHbQ2M26367pNPux5Uk50xMSSotLTX1Lisrc66NGfZPb6/b8c0ZEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADAi1EbxROLxZyjeCxxEv39/aZ1vPnmG861F194vql3RVmJc220wL1WkhKTKpxryye5R31IUi5ji7TJZd3jdbq6bFFJiiWcS/MhW4xMebF7rEk4Yovi6UslTfUhQ/9w3na3DsKBc21mwD0SSJKyhqe4ubztuAoC9/ogsD3X3v9eh6l+69atzrVtbW2m3pmM+20+adIkU+9Zs2Y5137mM59xrnV9nOUMCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAODFqM2CKykpUcQx/yoWizn3LSiwbXL73neca48cPmLqPalyonNtkM+ZeqdS7vle2ZwtgysUiZvqixMV7sV5W++tr+xzri2LTzD1bqh2z4KrqbMdV7mQbX9asswiYdv+jMh9LbmcLU8vn3fPGcwbs+BcsyIl6b33Dph6r//l06b6119/3bk2CNzvm5JtO9veseXMvfzyy4baPzjXuh4nnAEBALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALwYvVE8pWXOUTyp/j7nvkXFhaZ1FETcZ/Tut3aZek+cUOlcW1xYZOpdFHffzuJY1NQ7b4wzyuXdo5JefeOQqfe+jox7ceagqXdJzP02708NmHrnI7bYGUXc43IihugWSSqQ+1qMKTIKGdYSCbvd34/LBO7r/t3/+a2p92uvvGaqjxS4b2fUeH8z7U/35CNJUibjfv957dVXnGtd44Y4AwIAeGEaQM3NzbrkkktUVlam6upqXXvttWptbR1Sk0ql1NTUpIkTJ6q0tFTLly9XZ2fnsC4aADD2mQZQS0uLmpqatGXLFr3wwgvKZDK66qqr1NvbO1hz991365lnntGTTz6plpYW7d+/X9ddd92wLxwAMLaZfpn/3HPPDfn/2rVrVV1drW3btmnhwoXq7u7Wo48+qnXr1unKK6+UJD322GO68MILtWXLFl122WXDt3IAwJh2Rq8BdXd3S5IqKz94MX3btm3KZDJavHjxYM2sWbM0ZcoUbd68+YQ90um0ksnkkAsAYPw77QGUz+d111136fLLL9fs2bMlSR0dHYrFYqqoqBhSW1NTo46OjhP2aW5uViKRGLw0NDSc7pIAAGPIaQ+gpqYmvfrqq3riiSfOaAGrVq1Sd3f34KW9vf2M+gEAxobT+hzQHXfcoWeffVabNm3S5MmTB79eW1urgYEBdXV1DTkL6uzsVG1t7Ql7xeNxxeO2P8MMABj7TGdAQRDojjvu0Pr16/XSSy9p6tSpQ66fP3++otGoNmzYMPi11tZW7d27V42NjcOzYgDAuGA6A2pqatK6dev09NNPq6ysbPB1nUQioaKiIiUSCd18881auXKlKisrVV5erjvvvFONjY28Aw4AMIRpAK1Zs0aSdMUVVwz5+mOPPaYbb7xRkvTDH/5Q4XBYy5cvVzqd1pIlS/Twww8Py2IBAOOHaQC55PsUFhZq9erVWr169WkvSpLi8SIVOGaODQyknPuWlhWb1lFS5J4H9lbrblPvzEDWufbD7yw8lZqJ1c61lRWlpt7RcttrdtlQhXPtu21HTb3LSic41+bDPabe06fXONfmcu7HoCTls+7ZbpIUihgy74x5YEHI/TfxubwtDC4I3BcTj7lnBkrS4SNHnGvffP0NU+981pbVV2hYe8S4fyT3Y6UgYntZP8i7LyZk2JdBILncI8iCAwB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4cVp/juFsCMk9USQk93iQfM4WgZI1JI/09NviWFp3tznXRmNRU+/SuHvkUHlJoal3orrMVJ/KuffvMf5B3L50n3NtfY1t3Qrce2eytudysZh7xJMkRaPud9VQyJb1EgTusTNZY4RQJmOJkYmYencc2O9ce/T99029CyK2/Wm5yaOOEWPHJSrcj9tw2HYb9vW7H+M9SfcoK5fYNokzIACAJwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXozYLLpdNKyS3HKmepHuA2EC637SOZE+vc202sGVw5TNZ59o+Q60k9R4bcK49aovJUvjgAVN9xjnVT4oUlJt6Z/Puz6GKo3Wm3tt3pJ1rE2UxU++ykgpTfWmp++1SUlJi6m2pLyy09S4qcq8vKrLl4/X1ueeYDQy43x8kKRyxZS8q5B4aWVZuuw0LC+POtQUFtuPQIjOQca7N5/PSsVNnx3EGBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwYtRG8RSEAxWEHeMt8m6RPZL0XnunaR3prHvERqQgYuodibjXh0K2mJ9Qzv25RT7rfvtJUqrfFmdkeZqTTtsiUwK534a73jpk6r33HfeFlxS5x6VIUkX5BFP9xIlVzrWJRMLUu6yszLm2sLDY1Lu42L33xImVpt6HDx9xrg3kfj8+/h0WEya43+ZVVbbtLCoqdK5Np2335eJi9/0ZBO63SS6fV+eRw6es4wwIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4MWozYIrKYqpoMBteQ3n1Bv62rKskr29zrW5IG/qLUO2UjZny3jKZdzrs7b4NYVzMdta8lnn2rzxNrTkU+UNmYGSlDJE3g2kbDdissv9uJKkvXv3OdfGYrb9U1RUZKgtMfVOJCqcaysrbRlpnZ2WXEdbtlvINYfyP9XUuGf1Tayy5QCm0yn33qW2HMCDB93zEauq3Lcxm81qd9vbp6zjDAgA4IVpADU3N+uSSy5RWVmZqqurde2116q1tXVIzRVXXKFQKDTkcttttw3rogEAY59pALW0tKipqUlbtmzRCy+8oEwmo6uuukq9H/o11S233KIDBw4MXh588MFhXTQAYOwzvQb03HPPDfn/2rVrVV1drW3btmnhwoWDXy8uLlZtbe3wrBAAMC6d0WtA3d3dkj764uHPfvYzVVVVafbs2Vq1apX6+vo+tkc6nVYymRxyAQCMf6f9Lrh8Pq+77rpLl19+uWbPnj349a9+9as699xzVV9fr507d+pb3/qWWltb9ctf/vKEfZqbm3Xfffed7jIAAGPUaQ+gpqYmvfrqq/rtb3875Ou33nrr4L/nzJmjuro6LVq0SHv27NH06dM/0mfVqlVauXLl4P+TyaQaGhpOd1kAgDHitAbQHXfcoWeffVabNm3S5MmTT1q7YMECSdLu3btPOIDi8bji8fjpLAMAMIaZBlAQBLrzzju1fv16bdy4UVOnTj3l9+zYsUOSVFdXd1oLBACMT6YB1NTUpHXr1unpp59WWVmZOjo6JEmJREJFRUXas2eP1q1bpy984QuaOHGidu7cqbvvvlsLFy7U3LlzR2QDAABjk2kArVmzRtIHHzb9/z322GO68cYbFYvF9OKLL+qhhx5Sb2+vGhoatHz5cn3nO98ZtgUDAMYH86/gTqahoUEtLS1ntKDjCiJSNOJWW2LJsqq1ZcFNSB1zrj3WZ3sLeSaTGZFaScpk3XPPBrK2/LVcxpY1ljWsPZ9zz42TPsiccpXL2z51YLgJlbdFhykwZt7l8+716XTa1NtSf7TLdox3dh50ro1Go6belhxAaxZcJBIy1YcM5QMDtv1jkUrZekcijg+yksJh9/uPay1ZcAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAAL0777wGNtFDIPd4iHHKP2QgZaiWpIOSexxILG7JbJEVj7vM/iNribzKG6JaBnO02yWdtMSU5Q9RP1hhTkssa4ows2TqSMobyXM4YrRPY1pI1RhRZWGJ+AmPmkGXd1m20RMNY2WJ+pJKSEufa4uJC41rc90+0wH0dkk7616o/LJdzP2ZzebdazoAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXozaLLiS4hJFo27Lyw4MOPfNWbPGMu45TOGiuKm3Rd6QwyRJecNzC2sWnDX3zFKfy9qeE2Uy7oewJctKkvKG3LOssXcqa7vN0xn3zDtLtpskBYZ6465X3nBsWfdPIMttaDuucsb9c+TI+8618cJJpt7ZrHtGXpCPmnqnUinn2mjUvbfrfYczIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAF6M2iqe4uFixmFv0Q84xskeSgrhtk4uL3OMnMln3uBTJFoPR19dn6h2KuK87HrbFd1iiQSRbxIq198BAZETWYWWN4inI2KJeYtmYc20QWKOVLPvHGMNkqM8Y930+777uvK21OW6qq6vLuXbq1AZT7+7ug861h3qTpt7hsPs5SE9Pj3Ot6zHFGRAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADAi1GbBVdUXKR4zC3/KnDMjJOkIGfLa8tlB5xr0wNpU+9o1H3dkYjtucJA1j0PLBRxzxn7YC3u+WuSLZssk7Htn4IC90PYmgVnWbc1Cy5cYMsai+Xd681ZcIYMNmucniVTLZuxBbZZcgMzWdvCUyn3+70kHT36vnPte+8dMPWuP6fOuba/xHYbWvIoOzo6nGvzjscrZ0AAAC9MA2jNmjWaO3euysvLVV5ersbGRv3qV78avD6VSqmpqUkTJ05UaWmpli9frs7OzmFfNABg7DMNoMmTJ+uBBx7Qtm3b9PLLL+vKK6/UNddco9dee02SdPfdd+uZZ57Rk08+qZaWFu3fv1/XXXfdiCwcADC2mV4Duvrqq4f8/x/+4R+0Zs0abdmyRZMnT9ajjz6qdevW6corr5QkPfbYY7rwwgu1ZcsWXXbZZcO3agDAmHfarwHlcjk98cQT6u3tVWNjo7Zt26ZMJqPFixcP1syaNUtTpkzR5s2bP7ZPOp1WMpkccgEAjH/mAfTKK6+otLRU8Xhct912m9avX6+LLrpIHR0disViqqioGFJfU1Nz0ndPNDc3K5FIDF4aGmx/LRAAMDaZB9DMmTO1Y8cObd26VbfffrtWrFih119//bQXsGrVKnV3dw9e2tvbT7sXAGDsMH8OKBaL6fzzz5ckzZ8/X3/4wx/0ox/9SNdff70GBgbU1dU15Cyos7NTtbW1H9svHo8rHo/bVw4AGNPO+HNA+Xxe6XRa8+fPVzQa1YYNGwava21t1d69e9XY2HimPwYAMM6YzoBWrVqlZcuWacqUKerp6dG6deu0ceNGPf/880okErr55pu1cuVKVVZWqry8XHfeeacaGxt5BxwA4CNMA+jgwYP6+te/rgMHDiiRSGju3Ll6/vnn9Wd/9meSpB/+8IcKh8Navny50um0lixZoocffvi0FhYKhRQKhdxqw+4ncum0Me7DEA9ijXqxRNpEo7a4nHzgvhZjuorzfjmd+nDYFvMTjbr3tkYIWUQMsTCSpJCtPi7LbW6L4slk3W+XzIDtaDEkCClXYNs/WcO60wO2iCfXKJnB/mn3GK7du/eYeh871utcW1Bge5w4erTLudbyDmXXOCjTAHr00UdPen1hYaFWr16t1atXW9oCAD6ByIIDAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4YU7DHmnHIxwGLNEZhggcU19J2ax7fcYax2KQMUQCSVIma4nisT0PsUYOWWQN65akIHCPTLHGq1hkjbeJtV4jGMWTy7nfLpZayRjFY9w/lv1p3fd5xyiZ41yjZ06nt+X+FgpZo5LcbxfLNh6vPdX3hAJL17Ng3759/FE6ABgH2tvbNXny5I+9ftQNoHw+r/3796usrGxIiGUymVRDQ4Pa29tVXl7ucYUji+0cPz4J2yixnePNcGxnEATq6elRfX29wicJix51v4ILh8MnnZjl5eXjeucfx3aOH5+EbZTYzvHmTLczkUicsoY3IQAAvGAAAQC8GDMDKB6P695771U8Hve9lBHFdo4fn4RtlNjO8eZsbueoexMCAOCTYcycAQEAxhcGEADACwYQAMALBhAAwIsxM4BWr16t8847T4WFhVqwYIH+/d//3feShtX3vvc9hUKhIZdZs2b5XtYZ2bRpk66++mrV19crFArpqaeeGnJ9EAS65557VFdXp6KiIi1evFi7du3ys9gzcKrtvPHGGz+yb5cuXepnsaepublZl1xyicrKylRdXa1rr71Wra2tQ2pSqZSampo0ceJElZaWavny5ers7PS04tPjsp1XXHHFR/bnbbfd5mnFp2fNmjWaO3fu4IdNGxsb9atf/Wrw+rO1L8fEAPr5z3+ulStX6t5779Uf//hHzZs3T0uWLNHBgwd9L21YXXzxxTpw4MDg5be//a3vJZ2R3t5ezZs3T6tXrz7h9Q8++KB+/OMf65FHHtHWrVtVUlKiJUuWKJVKneWVnplTbackLV26dMi+ffzxx8/iCs9cS0uLmpqatGXLFr3wwgvKZDK66qqr1NvbO1hz991365lnntGTTz6plpYW7d+/X9ddd53HVdu5bKck3XLLLUP254MPPuhpxadn8uTJeuCBB7Rt2za9/PLLuvLKK3XNNdfotddek3QW92UwBlx66aVBU1PT4P9zuVxQX18fNDc3e1zV8Lr33nuDefPm+V7GiJEUrF+/fvD/+Xw+qK2tDb7//e8Pfq2rqyuIx+PB448/7mGFw+PD2xkEQbBixYrgmmuu8bKekXLw4MFAUtDS0hIEwQf7LhqNBk8++eRgzRtvvBFICjZv3uxrmWfsw9sZBEHwp3/6p8Ff/uVf+lvUCJkwYULwz//8z2d1X476M6CBgQFt27ZNixcvHvxaOBzW4sWLtXnzZo8rG367du1SfX29pk2bpq997Wvau3ev7yWNmLa2NnV0dAzZr4lEQgsWLBh3+1WSNm7cqOrqas2cOVO33367jhw54ntJZ6S7u1uSVFlZKUnatm2bMpnMkP05a9YsTZkyZUzvzw9v53E/+9nPVFVVpdmzZ2vVqlXq6+vzsbxhkcvl9MQTT6i3t1eNjY1ndV+OujDSDzt8+LByuZxqamqGfL2mpkZvvvmmp1UNvwULFmjt2rWaOXOmDhw4oPvuu0+f+9zn9Oqrr6qsrMz38oZdR0eHJJ1wvx6/brxYunSprrvuOk2dOlV79uzR3/7t32rZsmXavHmzIpGI7+WZ5fN53XXXXbr88ss1e/ZsSR/sz1gspoqKiiG1Y3l/nmg7JemrX/2qzj33XNXX12vnzp361re+pdbWVv3yl7/0uFq7V155RY2NjUqlUiotLdX69et10UUXaceOHWdtX476AfRJsWzZssF/z507VwsWLNC5556rX/ziF7r55ps9rgxn6oYbbhj895w5czR37lxNnz5dGzdu1KJFizyu7PQ0NTXp1VdfHfOvUZ7Kx23nrbfeOvjvOXPmqK6uTosWLdKePXs0ffr0s73M0zZz5kzt2LFD3d3d+td//VetWLFCLS0tZ3UNo/5XcFVVVYpEIh95B0ZnZ6dqa2s9rWrkVVRUaMaMGdq9e7fvpYyI4/vuk7ZfJWnatGmqqqoak/v2jjvu0LPPPqvf/OY3Q/5sSm1trQYGBtTV1TWkfqzuz4/bzhNZsGCBJI25/RmLxXT++edr/vz5am5u1rx58/SjH/3orO7LUT+AYrGY5s+frw0bNgx+LZ/Pa8OGDWpsbPS4spF17Ngx7dmzR3V1db6XMiKmTp2q2traIfs1mUxq69at43q/Sh/81d8jR46MqX0bBIHuuOMOrV+/Xi+99JKmTp065Pr58+crGo0O2Z+tra3au3fvmNqfp9rOE9mxY4ckjan9eSL5fF7pdPrs7sthfUvDCHniiSeCeDwerF27Nnj99deDW2+9NaioqAg6Ojp8L23Y/NVf/VWwcePGoK2tLfjd734XLF68OKiqqgoOHjzoe2mnraenJ9i+fXuwffv2QFLwgx/8INi+fXvw7rvvBkEQBA888EBQUVERPP3008HOnTuDa665Jpg6dWrQ39/veeU2J9vOnp6e4Jvf/GawefPmoK2tLXjxxReDT3/608EFF1wQpFIp30t3dvvttweJRCLYuHFjcODAgcFLX1/fYM1tt90WTJkyJXjppZeCl19+OWhsbAwaGxs9rtruVNu5e/fu4P777w9efvnloK2tLXj66aeDadOmBQsXLvS8cptvf/vbQUtLS9DW1hbs3Lkz+Pa3vx2EQqHg17/+dRAEZ29fjokBFARB8JOf/CSYMmVKEIvFgksvvTTYsmWL7yUNq+uvvz6oq6sLYrFYcM455wTXX399sHv3bt/LOiO/+c1vAkkfuaxYsSIIgg/eiv3d7343qKmpCeLxeLBo0aKgtbXV76JPw8m2s6+vL7jqqquCSZMmBdFoNDj33HODW265Zcw9eTrR9kkKHnvsscGa/v7+4C/+4i+CCRMmBMXFxcEXv/jF4MCBA/4WfRpOtZ179+4NFi5cGFRWVgbxeDw4//zzg7/+678Ouru7/S7c6Bvf+EZw7rnnBrFYLJg0aVKwaNGiweETBGdvX/LnGAAAXoz614AAAOMTAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgxf8FbX+GfwueslEAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#plotting an image from data\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(train_img[2005])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjkRLS-ogokR",
        "outputId": "696baf5a-b855-43b5-e92a-727482551867"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 59,  62,  63],\n",
              "        [ 43,  46,  45],\n",
              "        [ 50,  48,  43],\n",
              "        ...,\n",
              "        [158, 132, 108],\n",
              "        [152, 125, 102],\n",
              "        [148, 124, 103]],\n",
              "\n",
              "       [[ 16,  20,  20],\n",
              "        [  0,   0,   0],\n",
              "        [ 18,   8,   0],\n",
              "        ...,\n",
              "        [123,  88,  55],\n",
              "        [119,  83,  50],\n",
              "        [122,  87,  57]],\n",
              "\n",
              "       [[ 25,  24,  21],\n",
              "        [ 16,   7,   0],\n",
              "        [ 49,  27,   8],\n",
              "        ...,\n",
              "        [118,  84,  50],\n",
              "        [120,  84,  50],\n",
              "        [109,  73,  42]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[208, 170,  96],\n",
              "        [201, 153,  34],\n",
              "        [198, 161,  26],\n",
              "        ...,\n",
              "        [160, 133,  70],\n",
              "        [ 56,  31,   7],\n",
              "        [ 53,  34,  20]],\n",
              "\n",
              "       [[180, 139,  96],\n",
              "        [173, 123,  42],\n",
              "        [186, 144,  30],\n",
              "        ...,\n",
              "        [184, 148,  94],\n",
              "        [ 97,  62,  34],\n",
              "        [ 83,  53,  34]],\n",
              "\n",
              "       [[177, 144, 116],\n",
              "        [168, 129,  94],\n",
              "        [179, 142,  87],\n",
              "        ...,\n",
              "        [216, 184, 140],\n",
              "        [151, 118,  84],\n",
              "        [123,  92,  72]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "train_img[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix46d3PBigyp",
        "outputId": "445752c3-e935-4d01-a51d-c7760a581c56"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train_img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EOC3HoC6flg8"
      },
      "outputs": [],
      "source": [
        "# normalizing the images \n",
        "train_img = train_img/255.0\n",
        "test_img = test_img/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-H65eq_f1-H",
        "outputId": "5ea2f039-e79b-45ab-b605-4cc884f2645a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.10980392, 0.1372549 , 0.15294118],\n",
              "        [0.11764706, 0.13333333, 0.17254902],\n",
              "        [0.12941176, 0.17254902, 0.18431373],\n",
              "        ...,\n",
              "        [0.16862745, 0.21960784, 0.17647059],\n",
              "        [0.20392157, 0.25098039, 0.20784314],\n",
              "        [0.18039216, 0.22745098, 0.18431373]],\n",
              "\n",
              "       [[0.10588235, 0.11764706, 0.14901961],\n",
              "        [0.10588235, 0.10980392, 0.16078431],\n",
              "        [0.08235294, 0.12156863, 0.15294118],\n",
              "        ...,\n",
              "        [0.43921569, 0.53333333, 0.38039216],\n",
              "        [0.45882353, 0.54901961, 0.39607843],\n",
              "        [0.45098039, 0.54117647, 0.39215686]],\n",
              "\n",
              "       [[0.13333333, 0.14117647, 0.16470588],\n",
              "        [0.12941176, 0.12941176, 0.16862745],\n",
              "        [0.09411765, 0.11764706, 0.15686275],\n",
              "        ...,\n",
              "        [0.68627451, 0.81568627, 0.56078431],\n",
              "        [0.69411765, 0.81960784, 0.56470588],\n",
              "        [0.69019608, 0.81568627, 0.56078431]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.55686275, 0.69019608, 0.4627451 ],\n",
              "        [0.55686275, 0.69019608, 0.4627451 ],\n",
              "        [0.58823529, 0.72156863, 0.49803922],\n",
              "        ...,\n",
              "        [0.5254902 , 0.68627451, 0.46666667],\n",
              "        [0.50196078, 0.65882353, 0.43921569],\n",
              "        [0.5254902 , 0.68627451, 0.46666667]],\n",
              "\n",
              "       [[0.54901961, 0.69019608, 0.48627451],\n",
              "        [0.56862745, 0.70588235, 0.50588235],\n",
              "        [0.58823529, 0.72941176, 0.5254902 ],\n",
              "        ...,\n",
              "        [0.51372549, 0.66666667, 0.46666667],\n",
              "        [0.50980392, 0.66666667, 0.46666667],\n",
              "        [0.47843137, 0.63529412, 0.43529412]],\n",
              "\n",
              "       [[0.5254902 , 0.67058824, 0.48235294],\n",
              "        [0.53333333, 0.67058824, 0.48627451],\n",
              "        [0.53333333, 0.67058824, 0.48627451],\n",
              "        ...,\n",
              "        [0.41568627, 0.56470588, 0.39215686],\n",
              "        [0.40784314, 0.55686275, 0.38823529],\n",
              "        [0.39607843, 0.54901961, 0.37647059]]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train_img[7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sbtUgRQ1ikjE"
      },
      "outputs": [],
      "source": [
        "train_img = train_img.astype('float32')\n",
        "test_img = test_img.astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XZoGrpxEUSo-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import BatchNormalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJucyv90i70w"
      },
      "source": [
        "Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BdLNHAzKjELg"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "model1 = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "tf.keras.layers.MaxPooling2D(2, 2),\n",
        "#Add another convolution\n",
        "tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "\n",
        "#Now flatten the output. After this you'll just have the same DNN structure as the non convolutional version\n",
        "tf.keras.layers.Flatten(),\n",
        "#The same 128 dense layers, and 10 output layers as in the pre-convolution example:\n",
        "tf.keras.layers.Dense(128, activation='relu'),\n",
        "tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zto-3VBBqOPd",
        "outputId": "81be0665-d5ce-4ede-ac53-f6e49fca571d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 2, 2, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160,202\n",
            "Trainable params: 160,202\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF7QyKxwj6pa",
        "outputId": "2ad331da-e455-41d1-cf65-a5b86f730b9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1563/1563 [==============================] - 20s 6ms/step - loss: 1.4772 - accuracy: 0.4634 - val_loss: 1.2010 - val_accuracy: 0.5729\n",
            "Epoch 2/2\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0841 - accuracy: 0.6173 - val_loss: 1.0243 - val_accuracy: 0.6449\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdc0478b280>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# compiling\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "model1.compile('adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "model1.fit(train_img, to_categorical(train_lab), epochs = 2, verbose = 1, validation_data = (test_img, to_categorical(test_lab)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JgZUtlZj36-W"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Intermediate layer model, before data is fed into the xgboost"
      ],
      "metadata": {
        "id": "AupCOCyWqx-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flatten_model = tf.keras.Model(inputs = model1.inputs, outputs = model1.layers[6].output)"
      ],
      "metadata": {
        "id": "EmmC_9l3pV0-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flatten_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsLIC4gYqtCx",
        "outputId": "973b529b-66fc-452c-878f-90d7872ce241"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_input (InputLayer)   [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 2, 2, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93,248\n",
            "Trainable params: 93,248\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Values obtained from the flatten layer( Dataset for other models )"
      ],
      "metadata": {
        "id": "i1akOPtIx7Tc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_train = flatten_model.predict(train_img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yA7rWHZq24q",
        "outputId": "f792807e-fcd7-4590-acc8-6576e751ff60"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - 3s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxVMhGf2sraS",
        "outputId": "33f165d0-6969-4c22-863a-21ab0160777e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.49329597, 0.62983495,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.7473633 , 0.972875  , 0.        , 0.29410318, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.57831943, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.49271095, 0.        , 0.6433586 , 0.70790696, 0.46498024,\n",
              "       0.21094416, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.707688  ,\n",
              "       0.        , 0.        , 0.31148243, 0.        , 0.9353726 ,\n",
              "       0.        , 0.80415285, 0.        , 0.        , 0.6834446 ,\n",
              "       0.        , 0.        , 0.        , 0.0206577 , 0.        ,\n",
              "       0.8313874 , 0.        , 0.        , 0.3927369 , 0.        ,\n",
              "       0.        , 0.05240676, 0.15658095, 0.        , 0.24185108,\n",
              "       0.        , 0.        , 0.        , 0.7423878 , 0.        ,\n",
              "       0.        , 0.        , 1.0534463 , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.5722403 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.06493152, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.66065884, 0.        ,\n",
              "       0.4506043 , 0.14199063, 0.        , 0.        , 0.        ,\n",
              "       0.25328735, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.7610777 , 0.22274122, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.47423202, 0.        , 0.        ,\n",
              "       0.        , 0.24962631, 0.12265109, 0.        , 0.04329707,\n",
              "       0.        , 0.        , 0.10354683, 0.        , 0.        ,\n",
              "       0.        , 0.28324646, 0.        , 0.        , 1.2595847 ,\n",
              "       0.        , 0.15801875, 0.        , 0.        , 0.08528917,\n",
              "       0.        , 0.        , 0.        , 0.57278943, 0.04305869,\n",
              "       0.10950238, 0.        , 0.        , 0.3828467 , 0.        ,\n",
              "       0.9345676 , 0.        , 1.0893092 , 0.81216586, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.14416695, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.40284568, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.35478875, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.7013906 , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.15606974, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.39739782, 0.        ,\n",
              "       0.73391986, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.51518786, 0.        , 0.20402634, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.5458089 , 0.        , 0.        , 0.        , 0.19044289,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.43300837, 0.        , 0.        , 0.        , 0.27506432,\n",
              "       0.3526683 , 0.34132248, 0.00255289, 0.2628622 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.25435817, 0.        ,\n",
              "       0.        , 0.00595684, 0.23597297, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.5925738 , 0.        , 0.        , 0.        , 0.28074455,\n",
              "       0.9064333 , 0.        , 0.22547086, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.4667679 , 0.        , 0.        ,\n",
              "       0.        , 0.22316733, 1.5013916 , 0.        , 0.9198694 ,\n",
              "       0.1318965 , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.6522174 , 0.        , 0.38073775, 0.        ,\n",
              "       0.        , 0.3090602 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.2128086 , 0.        , 0.44873   , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.36293435,\n",
              "       0.5845355 , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.56956893, 0.        , 0.16489246, 0.        , 0.        ,\n",
              "       1.2936586 , 0.        , 0.        , 0.        , 0.39990488,\n",
              "       0.        , 0.7682748 , 0.        , 0.        , 0.8496104 ,\n",
              "       0.        , 0.4908109 , 0.03910379, 0.19640446, 0.06138425,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.3690597 ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.3634528 , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.20071049, 0.        , 0.20900226, 0.        , 0.6032153 ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.23566192, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.8765776 , 0.68490523,\n",
              "       0.        , 0.4905686 , 0.5869696 , 0.        , 0.07584071,\n",
              "       0.13772795, 1.0154102 , 0.        , 0.        , 0.65154254,\n",
              "       0.6121224 , 0.        , 0.57717246, 0.        , 0.        ,\n",
              "       0.47283477, 0.        , 0.        , 0.7427619 , 0.        ,\n",
              "       0.        , 0.        , 0.6842389 , 0.43287924, 0.        ,\n",
              "       0.18533646, 0.        , 0.        , 0.50278187, 0.        ,\n",
              "       0.34307382, 0.        , 0.49028865, 0.        , 0.08759941,\n",
              "       0.9341892 , 0.        , 0.6475997 , 0.        , 0.        ,\n",
              "       0.00725217, 0.        , 0.        , 0.        , 0.68844336,\n",
              "       0.12500066, 0.12714878, 0.        , 0.        , 0.26368943,\n",
              "       0.        , 0.3045166 , 0.07664175, 0.        , 0.82851654,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.05165462,\n",
              "       0.        , 0.2861723 , 0.        , 0.        , 0.        ,\n",
              "       0.00473551, 0.        , 0.2652834 , 0.87436974, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 1.0746951 , 0.        ,\n",
              "       0.        , 0.18503697, 0.        , 0.        , 0.39309198,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.4687135 ,\n",
              "       0.        , 0.        , 0.0960985 , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.5580289 , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.48530677, 0.        ,\n",
              "       0.        , 0.07368346, 0.        , 0.11938879, 0.        ,\n",
              "       0.        , 0.        , 0.4667347 , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.07039323, 0.82346183, 0.22786602, 0.        , 0.2902683 ,\n",
              "       0.2000094 , 0.        , 0.07835142, 0.        , 0.37258065,\n",
              "       0.        , 0.        , 0.12251125, 0.47782454, 0.        ,\n",
              "       0.1351114 , 0.        , 0.        , 0.17965287, 0.        ,\n",
              "       0.        , 0.7075665 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_test = flatten_model.predict(test_img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa2zlPpesYYh",
        "outputId": "f095fde6-6fcf-45b9-eb52-036e20e0c2ba"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBI3cTW6tWAT",
        "outputId": "754a60e5-0984-48e7-888e-93a9dd9aeea2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wL7WGOsnrLLj",
        "outputId": "d205cfea-40b6-41ab-a458-179878c49220"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(features_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6TA1cGktZpj",
        "outputId": "73afc12b-bc80-4d0e-b3c9-1e04fc626e2f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "KK8QBUX3Q_m5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.DataFrame(features_train)"
      ],
      "metadata": {
        "id": "7jFwVZurQ6Gp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "q7kzqjGJyOPO",
        "outputId": "808bd3ee-3783-42f5-a085-bdd363f00c5f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0    1    2         3         4         5         6         7    8    \\\n",
              "0  0.0  0.0  0.0  0.493296  0.629835  0.000000  0.000000  0.000000  0.0   \n",
              "1  0.0  0.0  0.0  0.441265  0.000000  0.065924  1.082605  0.242105  0.0   \n",
              "2  0.0  0.0  0.0  0.744404  0.146030  0.000000  0.527143  0.000000  0.0   \n",
              "3  0.0  0.0  0.0  0.322895  0.184838  0.000000  0.000000  0.000000  0.0   \n",
              "4  0.0  0.0  0.0  0.157811  0.080252  0.000000  0.164093  0.000000  0.0   \n",
              "\n",
              "        9    ...       502       503  504       505  506       507       508  \\\n",
              "0  0.000000  ...  0.122511  0.477825  0.0  0.135111  0.0  0.000000  0.179653   \n",
              "1  0.137061  ...  0.000000  0.007267  0.0  0.000000  0.0  0.000000  0.000000   \n",
              "2  0.816240  ...  0.163129  0.545806  0.0  0.000000  0.0  0.000000  0.137507   \n",
              "3  0.000000  ...  0.000000  0.693664  0.0  0.429647  0.0  0.097628  0.434761   \n",
              "4  0.000000  ...  0.000000  1.418861  0.0  0.169740  0.0  0.000000  0.000000   \n",
              "\n",
              "   509  510       511  \n",
              "0  0.0  0.0  0.707566  \n",
              "1  0.0  0.0  0.784829  \n",
              "2  0.0  0.0  0.947773  \n",
              "3  0.0  0.0  0.438663  \n",
              "4  0.0  0.0  1.162879  \n",
              "\n",
              "[5 rows x 512 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63addd2a-b186-4073-8894-4ea97ac2900e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>502</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.493296</td>\n",
              "      <td>0.629835</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.122511</td>\n",
              "      <td>0.477825</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.135111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.179653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.707566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.441265</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.065924</td>\n",
              "      <td>1.082605</td>\n",
              "      <td>0.242105</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137061</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007267</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.784829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.744404</td>\n",
              "      <td>0.146030</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.527143</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.816240</td>\n",
              "      <td>...</td>\n",
              "      <td>0.163129</td>\n",
              "      <td>0.545806</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.137507</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.947773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.322895</td>\n",
              "      <td>0.184838</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.693664</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.429647</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.097628</td>\n",
              "      <td>0.434761</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.438663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.157811</td>\n",
              "      <td>0.080252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.164093</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.418861</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.169740</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.162879</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 512 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63addd2a-b186-4073-8894-4ea97ac2900e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-63addd2a-b186-4073-8894-4ea97ac2900e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-63addd2a-b186-4073-8894-4ea97ac2900e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train_label'] = train_lab "
      ],
      "metadata": {
        "id": "8zNSFZNaRHMH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lab_train = dataset['train_label']"
      ],
      "metadata": {
        "id": "SHrH8piwyYYi"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_lab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgDBAxbkyRR6",
        "outputId": "81ed0aac-7755-4b9a-c142-54e291ed1339"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6],\n",
              "       [9],\n",
              "       [9],\n",
              "       ...,\n",
              "       [9],\n",
              "       [1],\n",
              "       [1]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "zfmDh648RQkU",
        "outputId": "a03a3522-5fd4-430c-c89b-5c6b8915162e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     0    1    2         3         4         5         6         7    8  \\\n",
              "0  0.0  0.0  0.0  0.493296  0.629835  0.000000  0.000000  0.000000  0.0   \n",
              "1  0.0  0.0  0.0  0.441265  0.000000  0.065924  1.082605  0.242105  0.0   \n",
              "2  0.0  0.0  0.0  0.744404  0.146030  0.000000  0.527143  0.000000  0.0   \n",
              "3  0.0  0.0  0.0  0.322895  0.184838  0.000000  0.000000  0.000000  0.0   \n",
              "4  0.0  0.0  0.0  0.157811  0.080252  0.000000  0.164093  0.000000  0.0   \n",
              "\n",
              "          9  ...       503  504       505  506       507       508  509  510  \\\n",
              "0  0.000000  ...  0.477825  0.0  0.135111  0.0  0.000000  0.179653  0.0  0.0   \n",
              "1  0.137061  ...  0.007267  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.0   \n",
              "2  0.816240  ...  0.545806  0.0  0.000000  0.0  0.000000  0.137507  0.0  0.0   \n",
              "3  0.000000  ...  0.693664  0.0  0.429647  0.0  0.097628  0.434761  0.0  0.0   \n",
              "4  0.000000  ...  1.418861  0.0  0.169740  0.0  0.000000  0.000000  0.0  0.0   \n",
              "\n",
              "        511  train_label  \n",
              "0  0.707566            6  \n",
              "1  0.784829            9  \n",
              "2  0.947773            9  \n",
              "3  0.438663            4  \n",
              "4  1.162879            1  \n",
              "\n",
              "[5 rows x 513 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c154947e-8bfb-415d-979d-018770a149f6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "      <th>train_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.493296</td>\n",
              "      <td>0.629835</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.477825</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.135111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.179653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.707566</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.441265</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.065924</td>\n",
              "      <td>1.082605</td>\n",
              "      <td>0.242105</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137061</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007267</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.784829</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.744404</td>\n",
              "      <td>0.146030</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.527143</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.816240</td>\n",
              "      <td>...</td>\n",
              "      <td>0.545806</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.137507</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.947773</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.322895</td>\n",
              "      <td>0.184838</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.693664</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.429647</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.097628</td>\n",
              "      <td>0.434761</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.438663</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.157811</td>\n",
              "      <td>0.080252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.164093</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.418861</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.169740</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.162879</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 513 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c154947e-8bfb-415d-979d-018770a149f6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c154947e-8bfb-415d-979d-018770a149f6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c154947e-8bfb-415d-979d-018770a149f6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLk6cfVxRYhd",
        "outputId": "09ae1628-ffb6-4531-8c4d-7debb9f11fef"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 513)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below - 'f' stands for feature"
      ],
      "metadata": {
        "id": "Smv1LaOJynHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_f_labels = dataset['train_label']"
      ],
      "metadata": {
        "id": "V193aCvBRg91"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_f_labels = train_f_labels.values"
      ],
      "metadata": {
        "id": "5eOofl6OSr_n"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train dataset which will get fed into models"
      ],
      "metadata": {
        "id": "ypLguHJLyuYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_f = dataset.drop(labels = ['train_label'], axis = 1)"
      ],
      "metadata": {
        "id": "tv2X2jgbSkxs"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_f = train_f.values"
      ],
      "metadata": {
        "id": "92FY_Ln3TQR6"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_f"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBgcvM3wTUeo",
        "outputId": "06288657-c4c1-483f-9948-7137d39617a8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.7075665 ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.7848292 ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.94777304],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.12106556],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.27280784],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.7535297 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "hFIFTod9tfru"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xg = xgb.XGBClassifier(objective = 'multi:softmax', num_class=10, n_estimators = 100, max_depth = 4, learning_rate = 0.1)"
      ],
      "metadata": {
        "id": "AALETPJbtnmz"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now, Train features and labels : train_f, train_f_labels\n",
        "##    Test features and labels : test_f, test_f_labels"
      ],
      "metadata": {
        "id": "mKan5f8r0Lr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xg.fit(train_f, train_f_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "Pc6JCvQb42qK",
        "outputId": "344ddeb3-cab8-4999-a288-f727e03ac6f6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_class=10,\n",
              "              num_parallel_tree=None, objective='multi:softmax', ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_class=10,\n",
              "              num_parallel_tree=None, objective=&#x27;multi:softmax&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_class=10,\n",
              "              num_parallel_tree=None, objective=&#x27;multi:softmax&#x27;, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_f_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPXqmpR1axEG",
        "outputId": "5bda55b6-b38b-4c53-f887-baa4950fc19b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 9, 9, ..., 9, 1, 1], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test dataset"
      ],
      "metadata": {
        "id": "n9BDjB9EzG52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_f = pd.DataFrame(features_test)"
      ],
      "metadata": {
        "id": "WqW1uty0ZQvD"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_f.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "6KCxJdxgZ7De",
        "outputId": "fbc0dcdb-e3c1-4e2b-e525-076a78b69814"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0    1    2         3         4    5         6         7    8         9    \\\n",
              "0  0.0  0.0  0.0  0.491068  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
              "1  0.0  0.0  0.0  0.000000  0.000000  0.0  1.298788  0.000000  0.0  0.000000   \n",
              "2  0.0  0.0  0.0  0.000000  0.000000  0.0  0.785201  0.125343  0.0  0.000000   \n",
              "3  0.0  0.0  0.0  0.000000  0.424195  0.0  0.000000  0.000000  0.0  0.000000   \n",
              "4  0.0  0.0  0.0  0.000000  0.791527  0.0  0.000000  0.036208  0.0  0.000000   \n",
              "5  0.0  0.0  0.0  0.057062  0.000000  0.0  0.000000  0.000000  0.0  0.028712   \n",
              "6  0.0  0.0  0.0  0.000000  0.000000  0.0  1.010507  0.000000  0.0  0.000000   \n",
              "7  0.0  0.0  0.0  0.091722  0.799515  0.0  0.000000  0.000000  0.0  0.000000   \n",
              "8  0.0  0.0  0.0  0.403434  0.000000  0.0  0.000000  0.000000  0.0  0.000000   \n",
              "9  0.0  0.0  0.0  0.368736  0.167414  0.0  0.348988  0.000000  0.0  0.000000   \n",
              "\n",
              "   ...       502       503  504       505  506       507       508  509  510  \\\n",
              "0  ...  0.000000  0.314028  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.0   \n",
              "1  ...  0.000000  0.546450  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.0   \n",
              "2  ...  0.000000  0.716498  0.0  0.066509  0.0  0.000000  0.000000  0.0  0.0   \n",
              "3  ...  0.000000  0.066152  0.0  0.564521  0.0  0.000000  0.000000  0.0  0.0   \n",
              "4  ...  0.630554  0.374637  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.0   \n",
              "5  ...  0.000000  0.000000  0.0  0.000000  0.0  0.000000  0.320136  0.0  0.0   \n",
              "6  ...  0.000000  0.157873  0.0  0.000000  0.0  0.000000  0.000000  0.0  0.0   \n",
              "7  ...  0.856983  0.301871  0.0  0.134252  0.0  0.139256  0.578731  0.0  0.0   \n",
              "8  ...  0.025495  0.732309  0.0  0.322726  0.0  0.000000  0.000000  0.0  0.0   \n",
              "9  ...  0.000000  0.139695  0.0  0.125926  0.0  0.000000  0.000000  0.0  0.0   \n",
              "\n",
              "        511  \n",
              "0  0.000000  \n",
              "1  0.211692  \n",
              "2  0.000000  \n",
              "3  0.650522  \n",
              "4  0.150672  \n",
              "5  0.193125  \n",
              "6  0.270918  \n",
              "7  0.250371  \n",
              "8  0.230992  \n",
              "9  0.425618  \n",
              "\n",
              "[10 rows x 512 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f6aefc6-dcc4-4179-9b27-48a74c24e432\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>502</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.491068</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.314028</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.298788</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.546450</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.211692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.785201</td>\n",
              "      <td>0.125343</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.716498</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.066509</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.424195</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066152</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.564521</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.650522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.791527</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.036208</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.630554</td>\n",
              "      <td>0.374637</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.150672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.057062</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.028712</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.320136</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.193125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.010507</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.157873</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.270918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.091722</td>\n",
              "      <td>0.799515</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.856983</td>\n",
              "      <td>0.301871</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.134252</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.139256</td>\n",
              "      <td>0.578731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.250371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.403434</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.025495</td>\n",
              "      <td>0.732309</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.322726</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.230992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.368736</td>\n",
              "      <td>0.167414</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.348988</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.139695</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125926</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.425618</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 512 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f6aefc6-dcc4-4179-9b27-48a74c24e432')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0f6aefc6-dcc4-4179-9b27-48a74c24e432 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0f6aefc6-dcc4-4179-9b27-48a74c24e432');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_f_labels = test_lab"
      ],
      "metadata": {
        "id": "95oPourHZoIm"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xg_predictions = xg.predict(test_f)"
      ],
      "metadata": {
        "id": "m87lftbZZD6k"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xg_predictions.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rZAdZ8zbNo3",
        "outputId": "44be6fbf-44e8-4d00-9c00-fc166bd2eb67"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "y-1UfshZb3dW"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(test_f_labels, xg_predictions)\n",
        "print('Accuracy: {:.2f}'.format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZBMwRkZbnmx",
        "outputId": "ffc35f01-6d21-4d47-eed1-7fcb4626f676"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm"
      ],
      "metadata": {
        "id": "4E59FerWs3Bt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78f42bd8-6318-468c-acf8-830de9733afb"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.9/dist-packages (3.3.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from lightgbm) (1.10.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from lightgbm) (0.40.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from lightgbm) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.9/dist-packages (from lightgbm) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb"
      ],
      "metadata": {
        "id": "U_R7c6m2zinJ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_clf = lgb.LGBMClassifier()"
      ],
      "metadata": {
        "id": "n119Q5i3zlj2"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_clf.fit(train_f, train_f_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "vAwXlJ8b0CKs",
        "outputId": "23c42ef2-40fe-4825-c835-6b8f30b104db"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_pred = lgb_clf.predict(test_f)"
      ],
      "metadata": {
        "id": "nFlvqIZV0zaq"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_lgb = accuracy_score(test_f_labels, lgb_pred)\n",
        "print('Accuracy: {:.2f}'.format(accuracy_lgb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKxZqtC71itC",
        "outputId": "7647e77d-40bc-44c5-a875-d21e9c88f5a7"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now, using CatBoost "
      ],
      "metadata": {
        "id": "AUXZ10Kv13px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMtLtYDe1n_a",
        "outputId": "164493bf-2d23-4f72-87a0-bf3742b4b635"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.1.1-cp39-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.9/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from catboost) (1.10.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.9/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.9/dist-packages (from catboost) (5.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from catboost) (1.22.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->catboost) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (1.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (23.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (5.12.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (8.4.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (4.39.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from plotly->catboost) (8.2.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->catboost) (3.15.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import catboost as cb"
      ],
      "metadata": {
        "id": "A5kRWk7t1_11"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cb_clf = cb.CatBoostClassifier()"
      ],
      "metadata": {
        "id": "9kEx4hOZ2FSc"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cb_clf.fit(train_f, train_f_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hgn-Va52O-y",
        "outputId": "96ab3c87-2584-4e44-d442-faf4488d35d8"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.096599\n",
            "0:\tlearn: 2.1859311\ttotal: 3.26s\tremaining: 54m 13s\n",
            "1:\tlearn: 2.0894578\ttotal: 5.26s\tremaining: 43m 44s\n",
            "2:\tlearn: 2.0114004\ttotal: 7.19s\tremaining: 39m 49s\n",
            "3:\tlearn: 1.9464813\ttotal: 9.18s\tremaining: 38m 5s\n",
            "4:\tlearn: 1.8892506\ttotal: 11.2s\tremaining: 37m\n",
            "5:\tlearn: 1.8403921\ttotal: 13.5s\tremaining: 37m 11s\n",
            "6:\tlearn: 1.7930598\ttotal: 16.3s\tremaining: 38m 29s\n",
            "7:\tlearn: 1.7517426\ttotal: 18.2s\tremaining: 37m 38s\n",
            "8:\tlearn: 1.7125592\ttotal: 20.2s\tremaining: 37m 5s\n",
            "9:\tlearn: 1.6775929\ttotal: 22.2s\tremaining: 36m 39s\n",
            "10:\tlearn: 1.6473685\ttotal: 24.2s\tremaining: 36m 13s\n",
            "11:\tlearn: 1.6186406\ttotal: 26.7s\tremaining: 36m 41s\n",
            "12:\tlearn: 1.5923197\ttotal: 29.3s\tremaining: 37m 1s\n",
            "13:\tlearn: 1.5684751\ttotal: 31.3s\tremaining: 36m 41s\n",
            "14:\tlearn: 1.5493087\ttotal: 33.3s\tremaining: 36m 24s\n",
            "15:\tlearn: 1.5282372\ttotal: 35.3s\tremaining: 36m 11s\n",
            "16:\tlearn: 1.5081006\ttotal: 37.3s\tremaining: 35m 55s\n",
            "17:\tlearn: 1.4899587\ttotal: 40.2s\tremaining: 36m 33s\n",
            "18:\tlearn: 1.4726653\ttotal: 42.4s\tremaining: 36m 29s\n",
            "19:\tlearn: 1.4565760\ttotal: 44.9s\tremaining: 36m 39s\n",
            "20:\tlearn: 1.4420532\ttotal: 46.8s\tremaining: 36m 23s\n",
            "21:\tlearn: 1.4265972\ttotal: 48.8s\tremaining: 36m 10s\n",
            "22:\tlearn: 1.4127545\ttotal: 50.9s\tremaining: 36m 3s\n",
            "23:\tlearn: 1.4010535\ttotal: 54s\tremaining: 36m 36s\n",
            "24:\tlearn: 1.3883496\ttotal: 56s\tremaining: 36m 23s\n",
            "25:\tlearn: 1.3761544\ttotal: 58s\tremaining: 36m 13s\n",
            "26:\tlearn: 1.3656248\ttotal: 60s\tremaining: 36m 1s\n",
            "27:\tlearn: 1.3548493\ttotal: 1m 1s\tremaining: 35m 51s\n",
            "28:\tlearn: 1.3435893\ttotal: 1m 4s\tremaining: 35m 53s\n",
            "29:\tlearn: 1.3332238\ttotal: 1m 7s\tremaining: 36m 9s\n",
            "30:\tlearn: 1.3233216\ttotal: 1m 9s\tremaining: 35m 58s\n",
            "31:\tlearn: 1.3143966\ttotal: 1m 11s\tremaining: 35m 48s\n",
            "32:\tlearn: 1.3062718\ttotal: 1m 12s\tremaining: 35m 38s\n",
            "33:\tlearn: 1.2979911\ttotal: 1m 14s\tremaining: 35m 29s\n",
            "34:\tlearn: 1.2893198\ttotal: 1m 17s\tremaining: 35m 41s\n",
            "35:\tlearn: 1.2817068\ttotal: 1m 20s\tremaining: 35m 42s\n",
            "36:\tlearn: 1.2738089\ttotal: 1m 21s\tremaining: 35m 33s\n",
            "37:\tlearn: 1.2660301\ttotal: 1m 23s\tremaining: 35m 24s\n",
            "38:\tlearn: 1.2583904\ttotal: 1m 25s\tremaining: 35m 17s\n",
            "39:\tlearn: 1.2504214\ttotal: 1m 27s\tremaining: 35m 9s\n",
            "40:\tlearn: 1.2435471\ttotal: 1m 31s\tremaining: 35m 42s\n",
            "41:\tlearn: 1.2379055\ttotal: 1m 33s\tremaining: 35m 33s\n",
            "42:\tlearn: 1.2316116\ttotal: 1m 35s\tremaining: 35m 26s\n",
            "43:\tlearn: 1.2256907\ttotal: 1m 37s\tremaining: 35m 19s\n",
            "44:\tlearn: 1.2197703\ttotal: 1m 39s\tremaining: 35m 11s\n",
            "45:\tlearn: 1.2136913\ttotal: 1m 41s\tremaining: 35m 4s\n",
            "46:\tlearn: 1.2084307\ttotal: 1m 44s\tremaining: 35m 20s\n",
            "47:\tlearn: 1.2024538\ttotal: 1m 46s\tremaining: 35m 14s\n",
            "48:\tlearn: 1.1972799\ttotal: 1m 48s\tremaining: 35m 7s\n",
            "49:\tlearn: 1.1916238\ttotal: 1m 50s\tremaining: 35m\n",
            "50:\tlearn: 1.1861258\ttotal: 1m 52s\tremaining: 34m 53s\n",
            "51:\tlearn: 1.1811249\ttotal: 1m 54s\tremaining: 34m 47s\n",
            "52:\tlearn: 1.1767633\ttotal: 1m 57s\tremaining: 35m 1s\n",
            "53:\tlearn: 1.1715726\ttotal: 1m 59s\tremaining: 34m 54s\n",
            "54:\tlearn: 1.1675891\ttotal: 2m 1s\tremaining: 34m 47s\n",
            "55:\tlearn: 1.1635144\ttotal: 2m 3s\tremaining: 34m 40s\n",
            "56:\tlearn: 1.1591217\ttotal: 2m 5s\tremaining: 34m 34s\n",
            "57:\tlearn: 1.1542116\ttotal: 2m 7s\tremaining: 34m 31s\n",
            "58:\tlearn: 1.1498438\ttotal: 2m 10s\tremaining: 34m 39s\n",
            "59:\tlearn: 1.1455727\ttotal: 2m 12s\tremaining: 34m 33s\n",
            "60:\tlearn: 1.1410314\ttotal: 2m 14s\tremaining: 34m 27s\n",
            "61:\tlearn: 1.1377128\ttotal: 2m 16s\tremaining: 34m 21s\n",
            "62:\tlearn: 1.1335401\ttotal: 2m 18s\tremaining: 34m 16s\n",
            "63:\tlearn: 1.1293028\ttotal: 2m 20s\tremaining: 34m 16s\n",
            "64:\tlearn: 1.1259786\ttotal: 2m 23s\tremaining: 34m 20s\n",
            "65:\tlearn: 1.1216023\ttotal: 2m 25s\tremaining: 34m 14s\n",
            "66:\tlearn: 1.1178841\ttotal: 2m 29s\tremaining: 34m 42s\n",
            "67:\tlearn: 1.1143463\ttotal: 2m 34s\tremaining: 35m 12s\n",
            "68:\tlearn: 1.1109435\ttotal: 2m 37s\tremaining: 35m 31s\n",
            "69:\tlearn: 1.1073097\ttotal: 2m 40s\tremaining: 35m 34s\n",
            "70:\tlearn: 1.1039948\ttotal: 2m 43s\tremaining: 35m 33s\n",
            "71:\tlearn: 1.1003537\ttotal: 2m 48s\tremaining: 36m 17s\n",
            "72:\tlearn: 1.0971518\ttotal: 2m 52s\tremaining: 36m 34s\n",
            "73:\tlearn: 1.0937240\ttotal: 2m 57s\tremaining: 36m 57s\n",
            "74:\tlearn: 1.0905838\ttotal: 3m 1s\tremaining: 37m 20s\n",
            "75:\tlearn: 1.0879040\ttotal: 3m 5s\tremaining: 37m 33s\n",
            "76:\tlearn: 1.0850047\ttotal: 3m 8s\tremaining: 37m 40s\n",
            "77:\tlearn: 1.0823885\ttotal: 3m 14s\tremaining: 38m 20s\n",
            "78:\tlearn: 1.0795405\ttotal: 3m 18s\tremaining: 38m 32s\n",
            "79:\tlearn: 1.0771888\ttotal: 3m 21s\tremaining: 38m 41s\n",
            "80:\tlearn: 1.0746804\ttotal: 3m 25s\tremaining: 38m 54s\n",
            "81:\tlearn: 1.0718705\ttotal: 3m 27s\tremaining: 38m 45s\n",
            "82:\tlearn: 1.0692715\ttotal: 3m 29s\tremaining: 38m 36s\n",
            "83:\tlearn: 1.0663545\ttotal: 3m 31s\tremaining: 38m 28s\n",
            "84:\tlearn: 1.0637193\ttotal: 3m 33s\tremaining: 38m 19s\n",
            "85:\tlearn: 1.0608966\ttotal: 3m 35s\tremaining: 38m 11s\n",
            "86:\tlearn: 1.0584968\ttotal: 3m 38s\tremaining: 38m 15s\n",
            "87:\tlearn: 1.0556668\ttotal: 3m 40s\tremaining: 38m 6s\n",
            "88:\tlearn: 1.0529543\ttotal: 3m 42s\tremaining: 37m 58s\n",
            "89:\tlearn: 1.0500219\ttotal: 3m 44s\tremaining: 37m 50s\n",
            "90:\tlearn: 1.0474720\ttotal: 3m 46s\tremaining: 37m 42s\n",
            "91:\tlearn: 1.0454192\ttotal: 3m 48s\tremaining: 37m 34s\n",
            "92:\tlearn: 1.0431447\ttotal: 3m 51s\tremaining: 37m 37s\n",
            "93:\tlearn: 1.0407821\ttotal: 3m 53s\tremaining: 37m 29s\n",
            "94:\tlearn: 1.0387394\ttotal: 3m 55s\tremaining: 37m 22s\n",
            "95:\tlearn: 1.0364927\ttotal: 3m 57s\tremaining: 37m 14s\n",
            "96:\tlearn: 1.0343621\ttotal: 3m 59s\tremaining: 37m 6s\n",
            "97:\tlearn: 1.0324964\ttotal: 4m 1s\tremaining: 36m 59s\n",
            "98:\tlearn: 1.0301531\ttotal: 4m 4s\tremaining: 37m 3s\n",
            "99:\tlearn: 1.0280618\ttotal: 4m 6s\tremaining: 36m 57s\n",
            "100:\tlearn: 1.0259101\ttotal: 4m 8s\tremaining: 36m 50s\n",
            "101:\tlearn: 1.0235193\ttotal: 4m 10s\tremaining: 36m 43s\n",
            "102:\tlearn: 1.0214008\ttotal: 4m 12s\tremaining: 36m 37s\n",
            "103:\tlearn: 1.0192893\ttotal: 4m 14s\tremaining: 36m 34s\n",
            "104:\tlearn: 1.0173929\ttotal: 4m 17s\tremaining: 36m 33s\n",
            "105:\tlearn: 1.0157588\ttotal: 4m 19s\tremaining: 36m 27s\n",
            "106:\tlearn: 1.0142136\ttotal: 4m 21s\tremaining: 36m 20s\n",
            "107:\tlearn: 1.0124595\ttotal: 4m 23s\tremaining: 36m 18s\n",
            "108:\tlearn: 1.0105399\ttotal: 4m 25s\tremaining: 36m 12s\n",
            "109:\tlearn: 1.0087930\ttotal: 4m 28s\tremaining: 36m 15s\n",
            "110:\tlearn: 1.0069720\ttotal: 4m 31s\tremaining: 36m 12s\n",
            "111:\tlearn: 1.0050419\ttotal: 4m 33s\tremaining: 36m 6s\n",
            "112:\tlearn: 1.0031134\ttotal: 4m 35s\tremaining: 36m 1s\n",
            "113:\tlearn: 1.0008226\ttotal: 4m 37s\tremaining: 35m 55s\n",
            "114:\tlearn: 0.9987393\ttotal: 4m 39s\tremaining: 35m 51s\n",
            "115:\tlearn: 0.9968529\ttotal: 4m 42s\tremaining: 35m 52s\n",
            "116:\tlearn: 0.9949758\ttotal: 4m 44s\tremaining: 35m 46s\n",
            "117:\tlearn: 0.9934138\ttotal: 4m 46s\tremaining: 35m 40s\n",
            "118:\tlearn: 0.9917279\ttotal: 4m 48s\tremaining: 35m 34s\n",
            "119:\tlearn: 0.9898002\ttotal: 4m 50s\tremaining: 35m 28s\n",
            "120:\tlearn: 0.9873916\ttotal: 4m 52s\tremaining: 35m 25s\n",
            "121:\tlearn: 0.9857143\ttotal: 4m 55s\tremaining: 35m 25s\n",
            "122:\tlearn: 0.9839474\ttotal: 4m 57s\tremaining: 35m 19s\n",
            "123:\tlearn: 0.9819116\ttotal: 4m 59s\tremaining: 35m 13s\n",
            "124:\tlearn: 0.9801391\ttotal: 5m 1s\tremaining: 35m 8s\n",
            "125:\tlearn: 0.9786503\ttotal: 5m 3s\tremaining: 35m 2s\n",
            "126:\tlearn: 0.9768267\ttotal: 5m 5s\tremaining: 35m 1s\n",
            "127:\tlearn: 0.9752613\ttotal: 5m 8s\tremaining: 34m 59s\n",
            "128:\tlearn: 0.9738985\ttotal: 5m 10s\tremaining: 34m 53s\n",
            "129:\tlearn: 0.9723222\ttotal: 5m 12s\tremaining: 34m 48s\n",
            "130:\tlearn: 0.9706626\ttotal: 5m 14s\tremaining: 34m 43s\n",
            "131:\tlearn: 0.9690668\ttotal: 5m 16s\tremaining: 34m 37s\n",
            "132:\tlearn: 0.9675350\ttotal: 5m 18s\tremaining: 34m 38s\n",
            "133:\tlearn: 0.9658843\ttotal: 5m 21s\tremaining: 34m 34s\n",
            "134:\tlearn: 0.9644375\ttotal: 5m 22s\tremaining: 34m 29s\n",
            "135:\tlearn: 0.9628161\ttotal: 5m 24s\tremaining: 34m 24s\n",
            "136:\tlearn: 0.9613896\ttotal: 5m 26s\tremaining: 34m 19s\n",
            "137:\tlearn: 0.9600217\ttotal: 5m 28s\tremaining: 34m 14s\n",
            "138:\tlearn: 0.9587597\ttotal: 5m 31s\tremaining: 34m 16s\n",
            "139:\tlearn: 0.9572776\ttotal: 5m 33s\tremaining: 34m 11s\n",
            "140:\tlearn: 0.9557675\ttotal: 5m 35s\tremaining: 34m 6s\n",
            "141:\tlearn: 0.9544170\ttotal: 5m 37s\tremaining: 34m 2s\n",
            "142:\tlearn: 0.9525977\ttotal: 5m 39s\tremaining: 33m 57s\n",
            "143:\tlearn: 0.9515686\ttotal: 5m 41s\tremaining: 33m 52s\n",
            "144:\tlearn: 0.9504221\ttotal: 5m 45s\tremaining: 33m 55s\n",
            "145:\tlearn: 0.9488690\ttotal: 5m 47s\tremaining: 33m 50s\n",
            "146:\tlearn: 0.9468673\ttotal: 5m 49s\tremaining: 33m 46s\n",
            "147:\tlearn: 0.9454216\ttotal: 5m 51s\tremaining: 33m 41s\n",
            "148:\tlearn: 0.9439591\ttotal: 5m 53s\tremaining: 33m 36s\n",
            "149:\tlearn: 0.9425873\ttotal: 5m 55s\tremaining: 33m 33s\n",
            "150:\tlearn: 0.9416517\ttotal: 5m 58s\tremaining: 33m 34s\n",
            "151:\tlearn: 0.9405370\ttotal: 6m\tremaining: 33m 29s\n",
            "152:\tlearn: 0.9391641\ttotal: 6m 2s\tremaining: 33m 25s\n",
            "153:\tlearn: 0.9380934\ttotal: 6m 4s\tremaining: 33m 20s\n",
            "154:\tlearn: 0.9369152\ttotal: 6m 6s\tremaining: 33m 16s\n",
            "155:\tlearn: 0.9354789\ttotal: 6m 8s\tremaining: 33m 16s\n",
            "156:\tlearn: 0.9341881\ttotal: 6m 12s\tremaining: 33m 17s\n",
            "157:\tlearn: 0.9327259\ttotal: 6m 14s\tremaining: 33m 13s\n",
            "158:\tlearn: 0.9312443\ttotal: 6m 16s\tremaining: 33m 8s\n",
            "159:\tlearn: 0.9300355\ttotal: 6m 18s\tremaining: 33m 7s\n",
            "160:\tlearn: 0.9288243\ttotal: 6m 21s\tremaining: 33m 9s\n",
            "161:\tlearn: 0.9273238\ttotal: 6m 24s\tremaining: 33m 7s\n",
            "162:\tlearn: 0.9260104\ttotal: 6m 26s\tremaining: 33m 3s\n",
            "163:\tlearn: 0.9247194\ttotal: 6m 28s\tremaining: 32m 58s\n",
            "164:\tlearn: 0.9235312\ttotal: 6m 30s\tremaining: 32m 54s\n",
            "165:\tlearn: 0.9221173\ttotal: 6m 32s\tremaining: 32m 50s\n",
            "166:\tlearn: 0.9207405\ttotal: 6m 35s\tremaining: 32m 51s\n",
            "167:\tlearn: 0.9193783\ttotal: 6m 37s\tremaining: 32m 47s\n",
            "168:\tlearn: 0.9179586\ttotal: 6m 39s\tremaining: 32m 43s\n",
            "169:\tlearn: 0.9166389\ttotal: 6m 41s\tremaining: 32m 39s\n",
            "170:\tlearn: 0.9150313\ttotal: 6m 43s\tremaining: 32m 35s\n",
            "171:\tlearn: 0.9140446\ttotal: 6m 45s\tremaining: 32m 30s\n",
            "172:\tlearn: 0.9129084\ttotal: 6m 48s\tremaining: 32m 32s\n",
            "173:\tlearn: 0.9116544\ttotal: 6m 50s\tremaining: 32m 28s\n",
            "174:\tlearn: 0.9105267\ttotal: 6m 52s\tremaining: 32m 24s\n",
            "175:\tlearn: 0.9093460\ttotal: 6m 54s\tremaining: 32m 20s\n",
            "176:\tlearn: 0.9079253\ttotal: 6m 56s\tremaining: 32m 16s\n",
            "177:\tlearn: 0.9064443\ttotal: 6m 58s\tremaining: 32m 14s\n",
            "178:\tlearn: 0.9053453\ttotal: 7m 1s\tremaining: 32m 14s\n",
            "179:\tlearn: 0.9043278\ttotal: 7m 3s\tremaining: 32m 10s\n",
            "180:\tlearn: 0.9032507\ttotal: 7m 5s\tremaining: 32m 6s\n",
            "181:\tlearn: 0.9023577\ttotal: 7m 7s\tremaining: 32m 2s\n",
            "182:\tlearn: 0.9012805\ttotal: 7m 9s\tremaining: 31m 58s\n",
            "183:\tlearn: 0.9000984\ttotal: 7m 12s\tremaining: 31m 57s\n",
            "184:\tlearn: 0.8992565\ttotal: 7m 14s\tremaining: 31m 56s\n",
            "185:\tlearn: 0.8979562\ttotal: 7m 16s\tremaining: 31m 52s\n",
            "186:\tlearn: 0.8964321\ttotal: 7m 19s\tremaining: 31m 48s\n",
            "187:\tlearn: 0.8953708\ttotal: 7m 20s\tremaining: 31m 44s\n",
            "188:\tlearn: 0.8943151\ttotal: 7m 22s\tremaining: 31m 40s\n",
            "189:\tlearn: 0.8932374\ttotal: 7m 25s\tremaining: 31m 41s\n",
            "190:\tlearn: 0.8921927\ttotal: 7m 28s\tremaining: 31m 37s\n",
            "191:\tlearn: 0.8910784\ttotal: 7m 29s\tremaining: 31m 33s\n",
            "192:\tlearn: 0.8899797\ttotal: 7m 31s\tremaining: 31m 29s\n",
            "193:\tlearn: 0.8885979\ttotal: 7m 33s\tremaining: 31m 25s\n",
            "194:\tlearn: 0.8877940\ttotal: 7m 35s\tremaining: 31m 22s\n",
            "195:\tlearn: 0.8864924\ttotal: 7m 39s\tremaining: 31m 23s\n",
            "196:\tlearn: 0.8855440\ttotal: 7m 41s\tremaining: 31m 19s\n",
            "197:\tlearn: 0.8846658\ttotal: 7m 43s\tremaining: 31m 15s\n",
            "198:\tlearn: 0.8837615\ttotal: 7m 44s\tremaining: 31m 11s\n",
            "199:\tlearn: 0.8828878\ttotal: 7m 46s\tremaining: 31m 7s\n",
            "200:\tlearn: 0.8821027\ttotal: 7m 48s\tremaining: 31m 4s\n",
            "201:\tlearn: 0.8809338\ttotal: 7m 52s\tremaining: 31m 5s\n",
            "202:\tlearn: 0.8794974\ttotal: 7m 54s\tremaining: 31m 1s\n",
            "203:\tlearn: 0.8784306\ttotal: 7m 56s\tremaining: 30m 57s\n",
            "204:\tlearn: 0.8773447\ttotal: 7m 58s\tremaining: 30m 54s\n",
            "205:\tlearn: 0.8764742\ttotal: 8m\tremaining: 30m 50s\n",
            "206:\tlearn: 0.8756460\ttotal: 8m 2s\tremaining: 30m 46s\n",
            "207:\tlearn: 0.8746300\ttotal: 8m 5s\tremaining: 30m 47s\n",
            "208:\tlearn: 0.8736813\ttotal: 8m 7s\tremaining: 30m 43s\n",
            "209:\tlearn: 0.8728935\ttotal: 8m 9s\tremaining: 30m 40s\n",
            "210:\tlearn: 0.8715515\ttotal: 8m 11s\tremaining: 30m 36s\n",
            "211:\tlearn: 0.8705624\ttotal: 8m 13s\tremaining: 30m 33s\n",
            "212:\tlearn: 0.8691417\ttotal: 8m 15s\tremaining: 30m 30s\n",
            "213:\tlearn: 0.8680997\ttotal: 8m 18s\tremaining: 30m 30s\n",
            "214:\tlearn: 0.8670698\ttotal: 8m 20s\tremaining: 30m 26s\n",
            "215:\tlearn: 0.8661343\ttotal: 8m 22s\tremaining: 30m 22s\n",
            "216:\tlearn: 0.8652049\ttotal: 8m 24s\tremaining: 30m 19s\n",
            "217:\tlearn: 0.8640880\ttotal: 8m 26s\tremaining: 30m 15s\n",
            "218:\tlearn: 0.8631173\ttotal: 8m 28s\tremaining: 30m 14s\n",
            "219:\tlearn: 0.8623947\ttotal: 8m 31s\tremaining: 30m 12s\n",
            "220:\tlearn: 0.8615330\ttotal: 8m 33s\tremaining: 30m 9s\n",
            "221:\tlearn: 0.8608590\ttotal: 8m 35s\tremaining: 30m 5s\n",
            "222:\tlearn: 0.8601333\ttotal: 8m 37s\tremaining: 30m 2s\n",
            "223:\tlearn: 0.8592719\ttotal: 8m 39s\tremaining: 29m 58s\n",
            "224:\tlearn: 0.8585169\ttotal: 8m 42s\tremaining: 29m 58s\n",
            "225:\tlearn: 0.8577487\ttotal: 8m 44s\tremaining: 29m 56s\n",
            "226:\tlearn: 0.8571067\ttotal: 8m 46s\tremaining: 29m 52s\n",
            "227:\tlearn: 0.8562357\ttotal: 8m 48s\tremaining: 29m 49s\n",
            "228:\tlearn: 0.8554595\ttotal: 8m 50s\tremaining: 29m 45s\n",
            "229:\tlearn: 0.8543945\ttotal: 8m 52s\tremaining: 29m 42s\n",
            "230:\tlearn: 0.8536795\ttotal: 8m 55s\tremaining: 29m 42s\n",
            "231:\tlearn: 0.8527071\ttotal: 8m 57s\tremaining: 29m 39s\n",
            "232:\tlearn: 0.8515980\ttotal: 8m 59s\tremaining: 29m 35s\n",
            "233:\tlearn: 0.8507307\ttotal: 9m 1s\tremaining: 29m 32s\n",
            "234:\tlearn: 0.8497073\ttotal: 9m 3s\tremaining: 29m 29s\n",
            "235:\tlearn: 0.8488301\ttotal: 9m 5s\tremaining: 29m 25s\n",
            "236:\tlearn: 0.8479410\ttotal: 9m 8s\tremaining: 29m 26s\n",
            "237:\tlearn: 0.8474901\ttotal: 9m 10s\tremaining: 29m 22s\n",
            "238:\tlearn: 0.8467670\ttotal: 9m 12s\tremaining: 29m 19s\n",
            "239:\tlearn: 0.8458474\ttotal: 9m 14s\tremaining: 29m 16s\n",
            "240:\tlearn: 0.8451679\ttotal: 9m 16s\tremaining: 29m 12s\n",
            "241:\tlearn: 0.8442485\ttotal: 9m 18s\tremaining: 29m 10s\n",
            "242:\tlearn: 0.8433490\ttotal: 9m 21s\tremaining: 29m 10s\n",
            "243:\tlearn: 0.8419723\ttotal: 9m 23s\tremaining: 29m 6s\n",
            "244:\tlearn: 0.8411047\ttotal: 9m 25s\tremaining: 29m 3s\n",
            "245:\tlearn: 0.8404281\ttotal: 9m 27s\tremaining: 29m\n",
            "246:\tlearn: 0.8396438\ttotal: 9m 29s\tremaining: 28m 56s\n",
            "247:\tlearn: 0.8390151\ttotal: 9m 31s\tremaining: 28m 54s\n",
            "248:\tlearn: 0.8380187\ttotal: 9m 34s\tremaining: 28m 53s\n",
            "249:\tlearn: 0.8370079\ttotal: 9m 36s\tremaining: 28m 50s\n",
            "250:\tlearn: 0.8360592\ttotal: 9m 38s\tremaining: 28m 47s\n",
            "251:\tlearn: 0.8348545\ttotal: 9m 40s\tremaining: 28m 44s\n",
            "252:\tlearn: 0.8341318\ttotal: 9m 42s\tremaining: 28m 40s\n",
            "253:\tlearn: 0.8330717\ttotal: 9m 45s\tremaining: 28m 39s\n",
            "254:\tlearn: 0.8322761\ttotal: 9m 47s\tremaining: 28m 37s\n",
            "255:\tlearn: 0.8313932\ttotal: 9m 49s\tremaining: 28m 34s\n",
            "256:\tlearn: 0.8305920\ttotal: 9m 51s\tremaining: 28m 30s\n",
            "257:\tlearn: 0.8296967\ttotal: 9m 53s\tremaining: 28m 27s\n",
            "258:\tlearn: 0.8288660\ttotal: 9m 55s\tremaining: 28m 24s\n",
            "259:\tlearn: 0.8282276\ttotal: 9m 58s\tremaining: 28m 24s\n",
            "260:\tlearn: 0.8272890\ttotal: 10m\tremaining: 28m 21s\n",
            "261:\tlearn: 0.8263018\ttotal: 10m 2s\tremaining: 28m 18s\n",
            "262:\tlearn: 0.8254134\ttotal: 10m 4s\tremaining: 28m 15s\n",
            "263:\tlearn: 0.8247326\ttotal: 10m 6s\tremaining: 28m 11s\n",
            "264:\tlearn: 0.8240700\ttotal: 10m 8s\tremaining: 28m 8s\n",
            "265:\tlearn: 0.8233055\ttotal: 10m 12s\tremaining: 28m 8s\n",
            "266:\tlearn: 0.8225301\ttotal: 10m 14s\tremaining: 28m 5s\n",
            "267:\tlearn: 0.8216781\ttotal: 10m 16s\tremaining: 28m 2s\n",
            "268:\tlearn: 0.8209539\ttotal: 10m 17s\tremaining: 27m 59s\n",
            "269:\tlearn: 0.8204856\ttotal: 10m 19s\tremaining: 27m 56s\n",
            "270:\tlearn: 0.8199274\ttotal: 10m 21s\tremaining: 27m 52s\n",
            "271:\tlearn: 0.8191684\ttotal: 10m 24s\tremaining: 27m 52s\n",
            "272:\tlearn: 0.8181856\ttotal: 10m 26s\tremaining: 27m 49s\n",
            "273:\tlearn: 0.8176045\ttotal: 10m 28s\tremaining: 27m 46s\n",
            "274:\tlearn: 0.8166303\ttotal: 10m 31s\tremaining: 27m 43s\n",
            "275:\tlearn: 0.8161477\ttotal: 10m 32s\tremaining: 27m 40s\n",
            "276:\tlearn: 0.8155119\ttotal: 10m 35s\tremaining: 27m 38s\n",
            "277:\tlearn: 0.8146878\ttotal: 10m 38s\tremaining: 27m 37s\n",
            "278:\tlearn: 0.8141491\ttotal: 10m 40s\tremaining: 27m 34s\n",
            "279:\tlearn: 0.8133145\ttotal: 10m 42s\tremaining: 27m 31s\n",
            "280:\tlearn: 0.8126110\ttotal: 10m 44s\tremaining: 27m 28s\n",
            "281:\tlearn: 0.8117752\ttotal: 10m 46s\tremaining: 27m 25s\n",
            "282:\tlearn: 0.8111792\ttotal: 10m 48s\tremaining: 27m 23s\n",
            "283:\tlearn: 0.8105405\ttotal: 10m 51s\tremaining: 27m 21s\n",
            "284:\tlearn: 0.8097687\ttotal: 10m 53s\tremaining: 27m 18s\n",
            "285:\tlearn: 0.8092820\ttotal: 10m 55s\tremaining: 27m 15s\n",
            "286:\tlearn: 0.8082880\ttotal: 10m 57s\tremaining: 27m 12s\n",
            "287:\tlearn: 0.8074458\ttotal: 10m 59s\tremaining: 27m 9s\n",
            "288:\tlearn: 0.8066919\ttotal: 11m 2s\tremaining: 27m 8s\n",
            "289:\tlearn: 0.8058074\ttotal: 11m 4s\tremaining: 27m 6s\n",
            "290:\tlearn: 0.8053630\ttotal: 11m 6s\tremaining: 27m 3s\n",
            "291:\tlearn: 0.8048239\ttotal: 11m 8s\tremaining: 27m\n",
            "292:\tlearn: 0.8040448\ttotal: 11m 10s\tremaining: 26m 57s\n",
            "293:\tlearn: 0.8033143\ttotal: 11m 12s\tremaining: 26m 54s\n",
            "294:\tlearn: 0.8027451\ttotal: 11m 15s\tremaining: 26m 54s\n",
            "295:\tlearn: 0.8021605\ttotal: 11m 17s\tremaining: 26m 51s\n",
            "296:\tlearn: 0.8013508\ttotal: 11m 19s\tremaining: 26m 48s\n",
            "297:\tlearn: 0.8006559\ttotal: 11m 21s\tremaining: 26m 45s\n",
            "298:\tlearn: 0.7997742\ttotal: 11m 23s\tremaining: 26m 42s\n",
            "299:\tlearn: 0.7988663\ttotal: 11m 25s\tremaining: 26m 38s\n",
            "300:\tlearn: 0.7982737\ttotal: 11m 28s\tremaining: 26m 38s\n",
            "301:\tlearn: 0.7977317\ttotal: 11m 30s\tremaining: 26m 35s\n",
            "302:\tlearn: 0.7969909\ttotal: 11m 32s\tremaining: 26m 32s\n",
            "303:\tlearn: 0.7962290\ttotal: 11m 34s\tremaining: 26m 29s\n",
            "304:\tlearn: 0.7957027\ttotal: 11m 36s\tremaining: 26m 26s\n",
            "305:\tlearn: 0.7952893\ttotal: 11m 38s\tremaining: 26m 23s\n",
            "306:\tlearn: 0.7946274\ttotal: 11m 41s\tremaining: 26m 23s\n",
            "307:\tlearn: 0.7940600\ttotal: 11m 43s\tremaining: 26m 20s\n",
            "308:\tlearn: 0.7935853\ttotal: 11m 45s\tremaining: 26m 17s\n",
            "309:\tlearn: 0.7930217\ttotal: 11m 47s\tremaining: 26m 14s\n",
            "310:\tlearn: 0.7926122\ttotal: 11m 49s\tremaining: 26m 11s\n",
            "311:\tlearn: 0.7921368\ttotal: 11m 51s\tremaining: 26m 9s\n",
            "312:\tlearn: 0.7911488\ttotal: 11m 54s\tremaining: 26m 7s\n",
            "313:\tlearn: 0.7904249\ttotal: 11m 56s\tremaining: 26m 4s\n",
            "314:\tlearn: 0.7897773\ttotal: 11m 58s\tremaining: 26m 1s\n",
            "315:\tlearn: 0.7889761\ttotal: 12m\tremaining: 25m 59s\n",
            "316:\tlearn: 0.7882318\ttotal: 12m 2s\tremaining: 25m 56s\n",
            "317:\tlearn: 0.7876503\ttotal: 12m 5s\tremaining: 25m 55s\n",
            "318:\tlearn: 0.7870756\ttotal: 12m 7s\tremaining: 25m 53s\n",
            "319:\tlearn: 0.7865773\ttotal: 12m 9s\tremaining: 25m 50s\n",
            "320:\tlearn: 0.7860158\ttotal: 12m 11s\tremaining: 25m 47s\n",
            "321:\tlearn: 0.7853527\ttotal: 12m 13s\tremaining: 25m 44s\n",
            "322:\tlearn: 0.7848234\ttotal: 12m 15s\tremaining: 25m 41s\n",
            "323:\tlearn: 0.7842799\ttotal: 12m 18s\tremaining: 25m 41s\n",
            "324:\tlearn: 0.7836449\ttotal: 12m 20s\tremaining: 25m 38s\n",
            "325:\tlearn: 0.7830017\ttotal: 12m 22s\tremaining: 25m 35s\n",
            "326:\tlearn: 0.7824061\ttotal: 12m 24s\tremaining: 25m 32s\n",
            "327:\tlearn: 0.7818886\ttotal: 12m 26s\tremaining: 25m 29s\n",
            "328:\tlearn: 0.7813287\ttotal: 12m 28s\tremaining: 25m 26s\n",
            "329:\tlearn: 0.7807704\ttotal: 12m 31s\tremaining: 25m 25s\n",
            "330:\tlearn: 0.7803095\ttotal: 12m 33s\tremaining: 25m 23s\n",
            "331:\tlearn: 0.7796011\ttotal: 12m 35s\tremaining: 25m 20s\n",
            "332:\tlearn: 0.7792259\ttotal: 12m 37s\tremaining: 25m 17s\n",
            "333:\tlearn: 0.7783909\ttotal: 12m 39s\tremaining: 25m 14s\n",
            "334:\tlearn: 0.7774796\ttotal: 12m 41s\tremaining: 25m 12s\n",
            "335:\tlearn: 0.7766257\ttotal: 12m 44s\tremaining: 25m 11s\n",
            "336:\tlearn: 0.7758932\ttotal: 12m 46s\tremaining: 25m 8s\n",
            "337:\tlearn: 0.7751929\ttotal: 12m 48s\tremaining: 25m 5s\n",
            "338:\tlearn: 0.7746162\ttotal: 12m 50s\tremaining: 25m 2s\n",
            "339:\tlearn: 0.7739143\ttotal: 12m 52s\tremaining: 24m 59s\n",
            "340:\tlearn: 0.7732776\ttotal: 12m 54s\tremaining: 24m 57s\n",
            "341:\tlearn: 0.7723444\ttotal: 12m 57s\tremaining: 24m 56s\n",
            "342:\tlearn: 0.7716212\ttotal: 12m 59s\tremaining: 24m 53s\n",
            "343:\tlearn: 0.7710621\ttotal: 13m 1s\tremaining: 24m 50s\n",
            "344:\tlearn: 0.7703540\ttotal: 13m 3s\tremaining: 24m 47s\n",
            "345:\tlearn: 0.7698016\ttotal: 13m 5s\tremaining: 24m 44s\n",
            "346:\tlearn: 0.7693548\ttotal: 13m 8s\tremaining: 24m 43s\n",
            "347:\tlearn: 0.7687358\ttotal: 13m 10s\tremaining: 24m 41s\n",
            "348:\tlearn: 0.7680891\ttotal: 13m 12s\tremaining: 24m 38s\n",
            "349:\tlearn: 0.7675683\ttotal: 13m 14s\tremaining: 24m 35s\n",
            "350:\tlearn: 0.7671900\ttotal: 13m 16s\tremaining: 24m 33s\n",
            "351:\tlearn: 0.7667715\ttotal: 13m 18s\tremaining: 24m 30s\n",
            "352:\tlearn: 0.7661841\ttotal: 13m 21s\tremaining: 24m 29s\n",
            "353:\tlearn: 0.7656632\ttotal: 13m 23s\tremaining: 24m 26s\n",
            "354:\tlearn: 0.7650925\ttotal: 13m 25s\tremaining: 24m 23s\n",
            "355:\tlearn: 0.7647314\ttotal: 13m 27s\tremaining: 24m 20s\n",
            "356:\tlearn: 0.7641370\ttotal: 13m 29s\tremaining: 24m 18s\n",
            "357:\tlearn: 0.7631746\ttotal: 13m 31s\tremaining: 24m 15s\n",
            "358:\tlearn: 0.7622548\ttotal: 13m 34s\tremaining: 24m 14s\n",
            "359:\tlearn: 0.7619511\ttotal: 13m 36s\tremaining: 24m 11s\n",
            "360:\tlearn: 0.7614894\ttotal: 13m 38s\tremaining: 24m 9s\n",
            "361:\tlearn: 0.7608177\ttotal: 13m 40s\tremaining: 24m 6s\n",
            "362:\tlearn: 0.7603143\ttotal: 13m 42s\tremaining: 24m 3s\n",
            "363:\tlearn: 0.7596725\ttotal: 13m 44s\tremaining: 24m 1s\n",
            "364:\tlearn: 0.7590103\ttotal: 13m 47s\tremaining: 24m\n",
            "365:\tlearn: 0.7585363\ttotal: 13m 49s\tremaining: 23m 57s\n",
            "366:\tlearn: 0.7580839\ttotal: 13m 51s\tremaining: 23m 54s\n",
            "367:\tlearn: 0.7575965\ttotal: 13m 53s\tremaining: 23m 51s\n",
            "368:\tlearn: 0.7573460\ttotal: 13m 55s\tremaining: 23m 49s\n",
            "369:\tlearn: 0.7566331\ttotal: 13m 58s\tremaining: 23m 47s\n",
            "370:\tlearn: 0.7556886\ttotal: 14m\tremaining: 23m 45s\n",
            "371:\tlearn: 0.7550951\ttotal: 14m 2s\tremaining: 23m 42s\n",
            "372:\tlearn: 0.7544196\ttotal: 14m 4s\tremaining: 23m 40s\n",
            "373:\tlearn: 0.7539301\ttotal: 14m 6s\tremaining: 23m 37s\n",
            "374:\tlearn: 0.7534351\ttotal: 14m 8s\tremaining: 23m 34s\n",
            "375:\tlearn: 0.7524194\ttotal: 14m 11s\tremaining: 23m 33s\n",
            "376:\tlearn: 0.7518470\ttotal: 14m 13s\tremaining: 23m 31s\n",
            "377:\tlearn: 0.7513335\ttotal: 14m 15s\tremaining: 23m 28s\n",
            "378:\tlearn: 0.7508356\ttotal: 14m 17s\tremaining: 23m 25s\n",
            "379:\tlearn: 0.7504245\ttotal: 14m 19s\tremaining: 23m 23s\n",
            "380:\tlearn: 0.7498821\ttotal: 14m 21s\tremaining: 23m 20s\n",
            "381:\tlearn: 0.7489960\ttotal: 14m 25s\tremaining: 23m 19s\n",
            "382:\tlearn: 0.7486253\ttotal: 14m 27s\tremaining: 23m 16s\n",
            "383:\tlearn: 0.7480497\ttotal: 14m 29s\tremaining: 23m 14s\n",
            "384:\tlearn: 0.7476968\ttotal: 14m 31s\tremaining: 23m 11s\n",
            "385:\tlearn: 0.7470621\ttotal: 14m 33s\tremaining: 23m 8s\n",
            "386:\tlearn: 0.7463046\ttotal: 14m 35s\tremaining: 23m 6s\n",
            "387:\tlearn: 0.7458517\ttotal: 14m 38s\tremaining: 23m 5s\n",
            "388:\tlearn: 0.7453701\ttotal: 14m 40s\tremaining: 23m 2s\n",
            "389:\tlearn: 0.7447578\ttotal: 14m 42s\tremaining: 22m 59s\n",
            "390:\tlearn: 0.7442083\ttotal: 14m 44s\tremaining: 22m 56s\n",
            "391:\tlearn: 0.7436287\ttotal: 14m 46s\tremaining: 22m 54s\n",
            "392:\tlearn: 0.7432368\ttotal: 14m 48s\tremaining: 22m 51s\n",
            "393:\tlearn: 0.7429193\ttotal: 14m 51s\tremaining: 22m 50s\n",
            "394:\tlearn: 0.7427194\ttotal: 14m 53s\tremaining: 22m 47s\n",
            "395:\tlearn: 0.7423149\ttotal: 14m 54s\tremaining: 22m 45s\n",
            "396:\tlearn: 0.7418124\ttotal: 14m 56s\tremaining: 22m 42s\n",
            "397:\tlearn: 0.7412455\ttotal: 14m 58s\tremaining: 22m 39s\n",
            "398:\tlearn: 0.7406360\ttotal: 15m 1s\tremaining: 22m 37s\n",
            "399:\tlearn: 0.7402793\ttotal: 15m 4s\tremaining: 22m 36s\n",
            "400:\tlearn: 0.7398802\ttotal: 15m 6s\tremaining: 22m 33s\n",
            "401:\tlearn: 0.7394324\ttotal: 15m 8s\tremaining: 22m 30s\n",
            "402:\tlearn: 0.7389694\ttotal: 15m 10s\tremaining: 22m 28s\n",
            "403:\tlearn: 0.7386856\ttotal: 15m 12s\tremaining: 22m 25s\n",
            "404:\tlearn: 0.7383155\ttotal: 15m 14s\tremaining: 22m 24s\n",
            "405:\tlearn: 0.7379163\ttotal: 15m 17s\tremaining: 22m 21s\n",
            "406:\tlearn: 0.7373198\ttotal: 15m 19s\tremaining: 22m 19s\n",
            "407:\tlearn: 0.7366394\ttotal: 15m 21s\tremaining: 22m 16s\n",
            "408:\tlearn: 0.7363308\ttotal: 15m 23s\tremaining: 22m 13s\n",
            "409:\tlearn: 0.7357061\ttotal: 15m 25s\tremaining: 22m 11s\n",
            "410:\tlearn: 0.7353498\ttotal: 15m 28s\tremaining: 22m 10s\n",
            "411:\tlearn: 0.7347833\ttotal: 15m 30s\tremaining: 22m 7s\n",
            "412:\tlearn: 0.7343076\ttotal: 15m 32s\tremaining: 22m 4s\n",
            "413:\tlearn: 0.7336264\ttotal: 15m 34s\tremaining: 22m 2s\n",
            "414:\tlearn: 0.7331724\ttotal: 15m 36s\tremaining: 21m 59s\n",
            "415:\tlearn: 0.7325732\ttotal: 15m 37s\tremaining: 21m 56s\n",
            "416:\tlearn: 0.7318591\ttotal: 15m 41s\tremaining: 21m 55s\n",
            "417:\tlearn: 0.7314985\ttotal: 15m 42s\tremaining: 21m 52s\n",
            "418:\tlearn: 0.7309419\ttotal: 15m 44s\tremaining: 21m 50s\n",
            "419:\tlearn: 0.7304662\ttotal: 15m 46s\tremaining: 21m 47s\n",
            "420:\tlearn: 0.7299313\ttotal: 15m 48s\tremaining: 21m 44s\n",
            "421:\tlearn: 0.7294489\ttotal: 15m 50s\tremaining: 21m 42s\n",
            "422:\tlearn: 0.7288779\ttotal: 15m 53s\tremaining: 21m 41s\n",
            "423:\tlearn: 0.7283842\ttotal: 15m 55s\tremaining: 21m 38s\n",
            "424:\tlearn: 0.7279550\ttotal: 15m 57s\tremaining: 21m 35s\n",
            "425:\tlearn: 0.7272771\ttotal: 15m 59s\tremaining: 21m 33s\n",
            "426:\tlearn: 0.7267005\ttotal: 16m 1s\tremaining: 21m 30s\n",
            "427:\tlearn: 0.7262186\ttotal: 16m 3s\tremaining: 21m 27s\n",
            "428:\tlearn: 0.7256657\ttotal: 16m 6s\tremaining: 21m 26s\n",
            "429:\tlearn: 0.7251471\ttotal: 16m 8s\tremaining: 21m 24s\n",
            "430:\tlearn: 0.7246606\ttotal: 16m 10s\tremaining: 21m 21s\n",
            "431:\tlearn: 0.7242437\ttotal: 16m 12s\tremaining: 21m 18s\n",
            "432:\tlearn: 0.7238295\ttotal: 16m 14s\tremaining: 21m 16s\n",
            "433:\tlearn: 0.7232471\ttotal: 16m 16s\tremaining: 21m 14s\n",
            "434:\tlearn: 0.7227837\ttotal: 16m 19s\tremaining: 21m 12s\n",
            "435:\tlearn: 0.7220855\ttotal: 16m 21s\tremaining: 21m 10s\n",
            "436:\tlearn: 0.7216302\ttotal: 16m 23s\tremaining: 21m 7s\n",
            "437:\tlearn: 0.7211085\ttotal: 16m 25s\tremaining: 21m 4s\n",
            "438:\tlearn: 0.7206988\ttotal: 16m 27s\tremaining: 21m 2s\n",
            "439:\tlearn: 0.7203184\ttotal: 16m 30s\tremaining: 21m\n",
            "440:\tlearn: 0.7195500\ttotal: 16m 32s\tremaining: 20m 58s\n",
            "441:\tlearn: 0.7192429\ttotal: 16m 34s\tremaining: 20m 55s\n",
            "442:\tlearn: 0.7186434\ttotal: 16m 36s\tremaining: 20m 53s\n",
            "443:\tlearn: 0.7180515\ttotal: 16m 38s\tremaining: 20m 50s\n",
            "444:\tlearn: 0.7175123\ttotal: 16m 40s\tremaining: 20m 47s\n",
            "445:\tlearn: 0.7167949\ttotal: 16m 43s\tremaining: 20m 46s\n",
            "446:\tlearn: 0.7162621\ttotal: 16m 45s\tremaining: 20m 44s\n",
            "447:\tlearn: 0.7158491\ttotal: 16m 47s\tremaining: 20m 41s\n",
            "448:\tlearn: 0.7154770\ttotal: 16m 49s\tremaining: 20m 38s\n",
            "449:\tlearn: 0.7150396\ttotal: 16m 51s\tremaining: 20m 36s\n",
            "450:\tlearn: 0.7146143\ttotal: 16m 53s\tremaining: 20m 33s\n",
            "451:\tlearn: 0.7141626\ttotal: 16m 56s\tremaining: 20m 32s\n",
            "452:\tlearn: 0.7135359\ttotal: 16m 58s\tremaining: 20m 29s\n",
            "453:\tlearn: 0.7128938\ttotal: 17m\tremaining: 20m 27s\n",
            "454:\tlearn: 0.7125010\ttotal: 17m 2s\tremaining: 20m 24s\n",
            "455:\tlearn: 0.7117776\ttotal: 17m 4s\tremaining: 20m 22s\n",
            "456:\tlearn: 0.7112617\ttotal: 17m 6s\tremaining: 20m 19s\n",
            "457:\tlearn: 0.7108632\ttotal: 17m 9s\tremaining: 20m 18s\n",
            "458:\tlearn: 0.7103200\ttotal: 17m 11s\tremaining: 20m 15s\n",
            "459:\tlearn: 0.7100385\ttotal: 17m 13s\tremaining: 20m 13s\n",
            "460:\tlearn: 0.7096282\ttotal: 17m 15s\tremaining: 20m 10s\n",
            "461:\tlearn: 0.7091419\ttotal: 17m 17s\tremaining: 20m 8s\n",
            "462:\tlearn: 0.7086502\ttotal: 17m 19s\tremaining: 20m 5s\n",
            "463:\tlearn: 0.7079664\ttotal: 17m 22s\tremaining: 20m 4s\n",
            "464:\tlearn: 0.7073523\ttotal: 17m 24s\tremaining: 20m 1s\n",
            "465:\tlearn: 0.7068451\ttotal: 17m 26s\tremaining: 19m 59s\n",
            "466:\tlearn: 0.7064719\ttotal: 17m 28s\tremaining: 19m 56s\n",
            "467:\tlearn: 0.7058949\ttotal: 17m 30s\tremaining: 19m 54s\n",
            "468:\tlearn: 0.7051111\ttotal: 17m 33s\tremaining: 19m 52s\n",
            "469:\tlearn: 0.7046012\ttotal: 17m 35s\tremaining: 19m 50s\n",
            "470:\tlearn: 0.7041376\ttotal: 17m 37s\tremaining: 19m 47s\n",
            "471:\tlearn: 0.7035291\ttotal: 17m 39s\tremaining: 19m 45s\n",
            "472:\tlearn: 0.7030562\ttotal: 17m 41s\tremaining: 19m 42s\n",
            "473:\tlearn: 0.7023594\ttotal: 17m 43s\tremaining: 19m 40s\n",
            "474:\tlearn: 0.7019725\ttotal: 17m 46s\tremaining: 19m 38s\n",
            "475:\tlearn: 0.7012955\ttotal: 17m 48s\tremaining: 19m 36s\n",
            "476:\tlearn: 0.7006468\ttotal: 17m 50s\tremaining: 19m 33s\n",
            "477:\tlearn: 0.7003249\ttotal: 17m 52s\tremaining: 19m 31s\n",
            "478:\tlearn: 0.6998623\ttotal: 17m 54s\tremaining: 19m 28s\n",
            "479:\tlearn: 0.6995022\ttotal: 17m 56s\tremaining: 19m 26s\n",
            "480:\tlearn: 0.6988618\ttotal: 17m 59s\tremaining: 19m 24s\n",
            "481:\tlearn: 0.6982664\ttotal: 18m 1s\tremaining: 19m 22s\n",
            "482:\tlearn: 0.6976828\ttotal: 18m 3s\tremaining: 19m 19s\n",
            "483:\tlearn: 0.6972218\ttotal: 18m 5s\tremaining: 19m 17s\n",
            "484:\tlearn: 0.6967856\ttotal: 18m 7s\tremaining: 19m 14s\n",
            "485:\tlearn: 0.6963972\ttotal: 18m 9s\tremaining: 19m 12s\n",
            "486:\tlearn: 0.6961383\ttotal: 18m 12s\tremaining: 19m 11s\n",
            "487:\tlearn: 0.6959380\ttotal: 18m 14s\tremaining: 19m 8s\n",
            "488:\tlearn: 0.6955233\ttotal: 18m 16s\tremaining: 19m 6s\n",
            "489:\tlearn: 0.6951173\ttotal: 18m 18s\tremaining: 19m 3s\n",
            "490:\tlearn: 0.6947455\ttotal: 18m 20s\tremaining: 19m 1s\n",
            "491:\tlearn: 0.6943033\ttotal: 18m 22s\tremaining: 18m 58s\n",
            "492:\tlearn: 0.6939214\ttotal: 18m 25s\tremaining: 18m 57s\n",
            "493:\tlearn: 0.6934337\ttotal: 18m 27s\tremaining: 18m 54s\n",
            "494:\tlearn: 0.6930815\ttotal: 18m 29s\tremaining: 18m 52s\n",
            "495:\tlearn: 0.6925229\ttotal: 18m 31s\tremaining: 18m 49s\n",
            "496:\tlearn: 0.6923043\ttotal: 18m 33s\tremaining: 18m 47s\n",
            "497:\tlearn: 0.6917050\ttotal: 18m 35s\tremaining: 18m 44s\n",
            "498:\tlearn: 0.6912467\ttotal: 18m 38s\tremaining: 18m 43s\n",
            "499:\tlearn: 0.6907461\ttotal: 18m 40s\tremaining: 18m 40s\n",
            "500:\tlearn: 0.6902677\ttotal: 18m 42s\tremaining: 18m 38s\n",
            "501:\tlearn: 0.6899737\ttotal: 18m 44s\tremaining: 18m 35s\n",
            "502:\tlearn: 0.6894743\ttotal: 18m 46s\tremaining: 18m 33s\n",
            "503:\tlearn: 0.6889895\ttotal: 18m 49s\tremaining: 18m 31s\n",
            "504:\tlearn: 0.6885511\ttotal: 18m 51s\tremaining: 18m 29s\n",
            "505:\tlearn: 0.6882949\ttotal: 18m 53s\tremaining: 18m 26s\n",
            "506:\tlearn: 0.6874769\ttotal: 18m 55s\tremaining: 18m 24s\n",
            "507:\tlearn: 0.6869904\ttotal: 18m 57s\tremaining: 18m 21s\n",
            "508:\tlearn: 0.6866263\ttotal: 18m 59s\tremaining: 18m 19s\n",
            "509:\tlearn: 0.6861125\ttotal: 19m 2s\tremaining: 18m 17s\n",
            "510:\tlearn: 0.6857370\ttotal: 19m 4s\tremaining: 18m 15s\n",
            "511:\tlearn: 0.6854604\ttotal: 19m 6s\tremaining: 18m 12s\n",
            "512:\tlearn: 0.6851063\ttotal: 19m 8s\tremaining: 18m 10s\n",
            "513:\tlearn: 0.6847415\ttotal: 19m 10s\tremaining: 18m 7s\n",
            "514:\tlearn: 0.6842520\ttotal: 19m 12s\tremaining: 18m 5s\n",
            "515:\tlearn: 0.6838558\ttotal: 19m 15s\tremaining: 18m 3s\n",
            "516:\tlearn: 0.6833973\ttotal: 19m 17s\tremaining: 18m 1s\n",
            "517:\tlearn: 0.6827866\ttotal: 19m 19s\tremaining: 17m 59s\n",
            "518:\tlearn: 0.6820660\ttotal: 19m 21s\tremaining: 17m 56s\n",
            "519:\tlearn: 0.6817892\ttotal: 19m 23s\tremaining: 17m 54s\n",
            "520:\tlearn: 0.6812452\ttotal: 19m 25s\tremaining: 17m 51s\n",
            "521:\tlearn: 0.6805043\ttotal: 19m 28s\tremaining: 17m 50s\n",
            "522:\tlearn: 0.6801354\ttotal: 19m 30s\tremaining: 17m 47s\n",
            "523:\tlearn: 0.6798113\ttotal: 19m 32s\tremaining: 17m 45s\n",
            "524:\tlearn: 0.6792670\ttotal: 19m 34s\tremaining: 17m 42s\n",
            "525:\tlearn: 0.6788083\ttotal: 19m 36s\tremaining: 17m 40s\n",
            "526:\tlearn: 0.6784569\ttotal: 19m 38s\tremaining: 17m 38s\n",
            "527:\tlearn: 0.6779036\ttotal: 19m 42s\tremaining: 17m 36s\n",
            "528:\tlearn: 0.6775866\ttotal: 19m 44s\tremaining: 17m 34s\n",
            "529:\tlearn: 0.6770029\ttotal: 19m 46s\tremaining: 17m 31s\n",
            "530:\tlearn: 0.6765009\ttotal: 19m 48s\tremaining: 17m 29s\n",
            "531:\tlearn: 0.6762025\ttotal: 19m 50s\tremaining: 17m 26s\n",
            "532:\tlearn: 0.6758769\ttotal: 19m 52s\tremaining: 17m 24s\n",
            "533:\tlearn: 0.6754706\ttotal: 19m 55s\tremaining: 17m 22s\n",
            "534:\tlearn: 0.6751742\ttotal: 19m 57s\tremaining: 17m 20s\n",
            "535:\tlearn: 0.6747085\ttotal: 19m 59s\tremaining: 17m 17s\n",
            "536:\tlearn: 0.6744179\ttotal: 20m\tremaining: 17m 15s\n",
            "537:\tlearn: 0.6740940\ttotal: 20m 2s\tremaining: 17m 12s\n",
            "538:\tlearn: 0.6737150\ttotal: 20m 5s\tremaining: 17m 11s\n",
            "539:\tlearn: 0.6734172\ttotal: 20m 8s\tremaining: 17m 9s\n",
            "540:\tlearn: 0.6729353\ttotal: 20m 9s\tremaining: 17m 6s\n",
            "541:\tlearn: 0.6725044\ttotal: 20m 11s\tremaining: 17m 4s\n",
            "542:\tlearn: 0.6720228\ttotal: 20m 13s\tremaining: 17m 1s\n",
            "543:\tlearn: 0.6717071\ttotal: 20m 15s\tremaining: 16m 59s\n",
            "544:\tlearn: 0.6713098\ttotal: 20m 19s\tremaining: 16m 57s\n",
            "545:\tlearn: 0.6709374\ttotal: 20m 21s\tremaining: 16m 55s\n",
            "546:\tlearn: 0.6704758\ttotal: 20m 23s\tremaining: 16m 52s\n",
            "547:\tlearn: 0.6701500\ttotal: 20m 25s\tremaining: 16m 50s\n",
            "548:\tlearn: 0.6696638\ttotal: 20m 27s\tremaining: 16m 48s\n",
            "549:\tlearn: 0.6693276\ttotal: 20m 29s\tremaining: 16m 45s\n",
            "550:\tlearn: 0.6689215\ttotal: 20m 32s\tremaining: 16m 44s\n",
            "551:\tlearn: 0.6683529\ttotal: 20m 34s\tremaining: 16m 41s\n",
            "552:\tlearn: 0.6678975\ttotal: 20m 36s\tremaining: 16m 39s\n",
            "553:\tlearn: 0.6675603\ttotal: 20m 38s\tremaining: 16m 37s\n",
            "554:\tlearn: 0.6672922\ttotal: 20m 40s\tremaining: 16m 34s\n",
            "555:\tlearn: 0.6669373\ttotal: 20m 42s\tremaining: 16m 32s\n",
            "556:\tlearn: 0.6666514\ttotal: 20m 45s\tremaining: 16m 30s\n",
            "557:\tlearn: 0.6662615\ttotal: 20m 47s\tremaining: 16m 28s\n",
            "558:\tlearn: 0.6659610\ttotal: 20m 49s\tremaining: 16m 25s\n",
            "559:\tlearn: 0.6655050\ttotal: 20m 51s\tremaining: 16m 23s\n",
            "560:\tlearn: 0.6651070\ttotal: 20m 53s\tremaining: 16m 21s\n",
            "561:\tlearn: 0.6644277\ttotal: 20m 56s\tremaining: 16m 19s\n",
            "562:\tlearn: 0.6642373\ttotal: 20m 58s\tremaining: 16m 17s\n",
            "563:\tlearn: 0.6639360\ttotal: 21m\tremaining: 16m 14s\n",
            "564:\tlearn: 0.6634911\ttotal: 21m 2s\tremaining: 16m 12s\n",
            "565:\tlearn: 0.6631676\ttotal: 21m 4s\tremaining: 16m 9s\n",
            "566:\tlearn: 0.6628961\ttotal: 21m 6s\tremaining: 16m 7s\n",
            "567:\tlearn: 0.6624594\ttotal: 21m 10s\tremaining: 16m 6s\n",
            "568:\tlearn: 0.6621967\ttotal: 21m 12s\tremaining: 16m 3s\n",
            "569:\tlearn: 0.6617976\ttotal: 21m 14s\tremaining: 16m 1s\n",
            "570:\tlearn: 0.6613997\ttotal: 21m 16s\tremaining: 15m 58s\n",
            "571:\tlearn: 0.6611520\ttotal: 21m 18s\tremaining: 15m 56s\n",
            "572:\tlearn: 0.6605887\ttotal: 21m 20s\tremaining: 15m 54s\n",
            "573:\tlearn: 0.6602859\ttotal: 21m 23s\tremaining: 15m 52s\n",
            "574:\tlearn: 0.6597956\ttotal: 21m 25s\tremaining: 15m 50s\n",
            "575:\tlearn: 0.6593096\ttotal: 21m 27s\tremaining: 15m 47s\n",
            "576:\tlearn: 0.6587382\ttotal: 21m 29s\tremaining: 15m 45s\n",
            "577:\tlearn: 0.6582004\ttotal: 21m 31s\tremaining: 15m 43s\n",
            "578:\tlearn: 0.6577274\ttotal: 21m 34s\tremaining: 15m 41s\n",
            "579:\tlearn: 0.6572554\ttotal: 21m 36s\tremaining: 15m 39s\n",
            "580:\tlearn: 0.6568102\ttotal: 21m 38s\tremaining: 15m 36s\n",
            "581:\tlearn: 0.6564761\ttotal: 21m 40s\tremaining: 15m 34s\n",
            "582:\tlearn: 0.6561493\ttotal: 21m 42s\tremaining: 15m 31s\n",
            "583:\tlearn: 0.6557810\ttotal: 21m 44s\tremaining: 15m 29s\n",
            "584:\tlearn: 0.6555106\ttotal: 21m 47s\tremaining: 15m 27s\n",
            "585:\tlearn: 0.6552424\ttotal: 21m 49s\tremaining: 15m 25s\n",
            "586:\tlearn: 0.6548601\ttotal: 21m 51s\tremaining: 15m 23s\n",
            "587:\tlearn: 0.6543699\ttotal: 21m 53s\tremaining: 15m 20s\n",
            "588:\tlearn: 0.6541095\ttotal: 21m 55s\tremaining: 15m 18s\n",
            "589:\tlearn: 0.6538113\ttotal: 21m 57s\tremaining: 15m 15s\n",
            "590:\tlearn: 0.6532784\ttotal: 22m\tremaining: 15m 14s\n",
            "591:\tlearn: 0.6531185\ttotal: 22m 2s\tremaining: 15m 11s\n",
            "592:\tlearn: 0.6526794\ttotal: 22m 4s\tremaining: 15m 9s\n",
            "593:\tlearn: 0.6523583\ttotal: 22m 6s\tremaining: 15m 6s\n",
            "594:\tlearn: 0.6520364\ttotal: 22m 8s\tremaining: 15m 4s\n",
            "595:\tlearn: 0.6513544\ttotal: 22m 11s\tremaining: 15m 2s\n",
            "596:\tlearn: 0.6510014\ttotal: 22m 14s\tremaining: 15m\n",
            "597:\tlearn: 0.6506508\ttotal: 22m 16s\tremaining: 14m 58s\n",
            "598:\tlearn: 0.6502613\ttotal: 22m 18s\tremaining: 14m 55s\n",
            "599:\tlearn: 0.6498195\ttotal: 22m 20s\tremaining: 14m 53s\n",
            "600:\tlearn: 0.6496386\ttotal: 22m 22s\tremaining: 14m 50s\n",
            "601:\tlearn: 0.6492746\ttotal: 22m 24s\tremaining: 14m 48s\n",
            "602:\tlearn: 0.6489288\ttotal: 22m 27s\tremaining: 14m 46s\n",
            "603:\tlearn: 0.6487182\ttotal: 22m 29s\tremaining: 14m 44s\n",
            "604:\tlearn: 0.6481137\ttotal: 22m 31s\tremaining: 14m 42s\n",
            "605:\tlearn: 0.6478746\ttotal: 22m 33s\tremaining: 14m 39s\n",
            "606:\tlearn: 0.6473910\ttotal: 22m 35s\tremaining: 14m 37s\n",
            "607:\tlearn: 0.6471334\ttotal: 22m 37s\tremaining: 14m 35s\n",
            "608:\tlearn: 0.6467634\ttotal: 22m 40s\tremaining: 14m 33s\n",
            "609:\tlearn: 0.6464729\ttotal: 22m 42s\tremaining: 14m 30s\n",
            "610:\tlearn: 0.6461211\ttotal: 22m 43s\tremaining: 14m 28s\n",
            "611:\tlearn: 0.6458304\ttotal: 22m 45s\tremaining: 14m 25s\n",
            "612:\tlearn: 0.6453688\ttotal: 22m 47s\tremaining: 14m 23s\n",
            "613:\tlearn: 0.6450690\ttotal: 22m 50s\tremaining: 14m 21s\n",
            "614:\tlearn: 0.6447800\ttotal: 22m 53s\tremaining: 14m 19s\n",
            "615:\tlearn: 0.6444594\ttotal: 22m 54s\tremaining: 14m 17s\n",
            "616:\tlearn: 0.6440729\ttotal: 22m 56s\tremaining: 14m 14s\n",
            "617:\tlearn: 0.6439106\ttotal: 22m 58s\tremaining: 14m 12s\n",
            "618:\tlearn: 0.6436211\ttotal: 23m\tremaining: 14m 9s\n",
            "619:\tlearn: 0.6431557\ttotal: 23m 3s\tremaining: 14m 8s\n",
            "620:\tlearn: 0.6427190\ttotal: 23m 5s\tremaining: 14m 5s\n",
            "621:\tlearn: 0.6423568\ttotal: 23m 7s\tremaining: 14m 3s\n",
            "622:\tlearn: 0.6420441\ttotal: 23m 9s\tremaining: 14m 1s\n",
            "623:\tlearn: 0.6414144\ttotal: 23m 11s\tremaining: 13m 58s\n",
            "624:\tlearn: 0.6409672\ttotal: 23m 13s\tremaining: 13m 56s\n",
            "625:\tlearn: 0.6407311\ttotal: 23m 16s\tremaining: 13m 54s\n",
            "626:\tlearn: 0.6405054\ttotal: 23m 18s\tremaining: 13m 52s\n",
            "627:\tlearn: 0.6399871\ttotal: 23m 20s\tremaining: 13m 49s\n",
            "628:\tlearn: 0.6397706\ttotal: 23m 22s\tremaining: 13m 47s\n",
            "629:\tlearn: 0.6393938\ttotal: 23m 24s\tremaining: 13m 45s\n",
            "630:\tlearn: 0.6392573\ttotal: 23m 26s\tremaining: 13m 42s\n",
            "631:\tlearn: 0.6388711\ttotal: 23m 30s\tremaining: 13m 41s\n",
            "632:\tlearn: 0.6385713\ttotal: 23m 32s\tremaining: 13m 38s\n",
            "633:\tlearn: 0.6382074\ttotal: 23m 33s\tremaining: 13m 36s\n",
            "634:\tlearn: 0.6376766\ttotal: 23m 35s\tremaining: 13m 33s\n",
            "635:\tlearn: 0.6371343\ttotal: 23m 37s\tremaining: 13m 31s\n",
            "636:\tlearn: 0.6366148\ttotal: 23m 39s\tremaining: 13m 29s\n",
            "637:\tlearn: 0.6361803\ttotal: 23m 43s\tremaining: 13m 27s\n",
            "638:\tlearn: 0.6358320\ttotal: 23m 45s\tremaining: 13m 25s\n",
            "639:\tlearn: 0.6355892\ttotal: 23m 46s\tremaining: 13m 22s\n",
            "640:\tlearn: 0.6351816\ttotal: 23m 48s\tremaining: 13m 20s\n",
            "641:\tlearn: 0.6349051\ttotal: 23m 50s\tremaining: 13m 17s\n",
            "642:\tlearn: 0.6344358\ttotal: 23m 53s\tremaining: 13m 15s\n",
            "643:\tlearn: 0.6338724\ttotal: 23m 56s\tremaining: 13m 13s\n",
            "644:\tlearn: 0.6336239\ttotal: 23m 58s\tremaining: 13m 11s\n",
            "645:\tlearn: 0.6331775\ttotal: 24m\tremaining: 13m 9s\n",
            "646:\tlearn: 0.6328453\ttotal: 24m 2s\tremaining: 13m 6s\n",
            "647:\tlearn: 0.6326067\ttotal: 24m 3s\tremaining: 13m 4s\n",
            "648:\tlearn: 0.6321111\ttotal: 24m 6s\tremaining: 13m 2s\n",
            "649:\tlearn: 0.6318805\ttotal: 24m 9s\tremaining: 13m\n",
            "650:\tlearn: 0.6316172\ttotal: 24m 11s\tremaining: 12m 57s\n",
            "651:\tlearn: 0.6313611\ttotal: 24m 13s\tremaining: 12m 55s\n",
            "652:\tlearn: 0.6308957\ttotal: 24m 15s\tremaining: 12m 53s\n",
            "653:\tlearn: 0.6306748\ttotal: 24m 17s\tremaining: 12m 50s\n",
            "654:\tlearn: 0.6304623\ttotal: 24m 19s\tremaining: 12m 48s\n",
            "655:\tlearn: 0.6302111\ttotal: 24m 22s\tremaining: 12m 46s\n",
            "656:\tlearn: 0.6297603\ttotal: 24m 24s\tremaining: 12m 44s\n",
            "657:\tlearn: 0.6294204\ttotal: 24m 26s\tremaining: 12m 42s\n",
            "658:\tlearn: 0.6292000\ttotal: 24m 28s\tremaining: 12m 39s\n",
            "659:\tlearn: 0.6288923\ttotal: 24m 30s\tremaining: 12m 37s\n",
            "660:\tlearn: 0.6285793\ttotal: 24m 33s\tremaining: 12m 35s\n",
            "661:\tlearn: 0.6283212\ttotal: 24m 35s\tremaining: 12m 33s\n",
            "662:\tlearn: 0.6280328\ttotal: 24m 37s\tremaining: 12m 30s\n",
            "663:\tlearn: 0.6277421\ttotal: 24m 39s\tremaining: 12m 28s\n",
            "664:\tlearn: 0.6273050\ttotal: 24m 41s\tremaining: 12m 26s\n",
            "665:\tlearn: 0.6270510\ttotal: 24m 43s\tremaining: 12m 23s\n",
            "666:\tlearn: 0.6267191\ttotal: 24m 46s\tremaining: 12m 22s\n",
            "667:\tlearn: 0.6264303\ttotal: 24m 48s\tremaining: 12m 19s\n",
            "668:\tlearn: 0.6262084\ttotal: 24m 50s\tremaining: 12m 17s\n",
            "669:\tlearn: 0.6258970\ttotal: 24m 52s\tremaining: 12m 15s\n",
            "670:\tlearn: 0.6255208\ttotal: 24m 54s\tremaining: 12m 12s\n",
            "671:\tlearn: 0.6249021\ttotal: 24m 56s\tremaining: 12m 10s\n",
            "672:\tlearn: 0.6246104\ttotal: 24m 59s\tremaining: 12m 8s\n",
            "673:\tlearn: 0.6240941\ttotal: 25m 1s\tremaining: 12m 6s\n",
            "674:\tlearn: 0.6235049\ttotal: 25m 3s\tremaining: 12m 3s\n",
            "675:\tlearn: 0.6232747\ttotal: 25m 5s\tremaining: 12m 1s\n",
            "676:\tlearn: 0.6229914\ttotal: 25m 7s\tremaining: 11m 59s\n",
            "677:\tlearn: 0.6226450\ttotal: 25m 9s\tremaining: 11m 57s\n",
            "678:\tlearn: 0.6224106\ttotal: 25m 12s\tremaining: 11m 55s\n",
            "679:\tlearn: 0.6221299\ttotal: 25m 14s\tremaining: 11m 52s\n",
            "680:\tlearn: 0.6218474\ttotal: 25m 16s\tremaining: 11m 50s\n",
            "681:\tlearn: 0.6214986\ttotal: 25m 18s\tremaining: 11m 48s\n",
            "682:\tlearn: 0.6211917\ttotal: 25m 20s\tremaining: 11m 45s\n",
            "683:\tlearn: 0.6208985\ttotal: 25m 23s\tremaining: 11m 43s\n",
            "684:\tlearn: 0.6205012\ttotal: 25m 26s\tremaining: 11m 41s\n",
            "685:\tlearn: 0.6200676\ttotal: 25m 28s\tremaining: 11m 39s\n",
            "686:\tlearn: 0.6198918\ttotal: 25m 30s\tremaining: 11m 37s\n",
            "687:\tlearn: 0.6196710\ttotal: 25m 32s\tremaining: 11m 34s\n",
            "688:\tlearn: 0.6192467\ttotal: 25m 34s\tremaining: 11m 32s\n",
            "689:\tlearn: 0.6190856\ttotal: 25m 37s\tremaining: 11m 30s\n",
            "690:\tlearn: 0.6186722\ttotal: 25m 39s\tremaining: 11m 28s\n",
            "691:\tlearn: 0.6181291\ttotal: 25m 41s\tremaining: 11m 26s\n",
            "692:\tlearn: 0.6179801\ttotal: 25m 43s\tremaining: 11m 23s\n",
            "693:\tlearn: 0.6176579\ttotal: 25m 45s\tremaining: 11m 21s\n",
            "694:\tlearn: 0.6173036\ttotal: 25m 47s\tremaining: 11m 18s\n",
            "695:\tlearn: 0.6169558\ttotal: 25m 50s\tremaining: 11m 17s\n",
            "696:\tlearn: 0.6167111\ttotal: 25m 52s\tremaining: 11m 14s\n",
            "697:\tlearn: 0.6161213\ttotal: 25m 54s\tremaining: 11m 12s\n",
            "698:\tlearn: 0.6158658\ttotal: 25m 56s\tremaining: 11m 10s\n",
            "699:\tlearn: 0.6154281\ttotal: 25m 58s\tremaining: 11m 7s\n",
            "700:\tlearn: 0.6150476\ttotal: 26m\tremaining: 11m 5s\n",
            "701:\tlearn: 0.6146455\ttotal: 26m 3s\tremaining: 11m 3s\n",
            "702:\tlearn: 0.6142909\ttotal: 26m 5s\tremaining: 11m 1s\n",
            "703:\tlearn: 0.6139486\ttotal: 26m 7s\tremaining: 10m 59s\n",
            "704:\tlearn: 0.6135458\ttotal: 26m 9s\tremaining: 10m 56s\n",
            "705:\tlearn: 0.6132617\ttotal: 26m 11s\tremaining: 10m 54s\n",
            "706:\tlearn: 0.6129940\ttotal: 26m 14s\tremaining: 10m 52s\n",
            "707:\tlearn: 0.6124090\ttotal: 26m 16s\tremaining: 10m 50s\n",
            "708:\tlearn: 0.6120865\ttotal: 26m 18s\tremaining: 10m 47s\n",
            "709:\tlearn: 0.6117398\ttotal: 26m 20s\tremaining: 10m 45s\n",
            "710:\tlearn: 0.6116004\ttotal: 26m 22s\tremaining: 10m 43s\n",
            "711:\tlearn: 0.6113215\ttotal: 26m 24s\tremaining: 10m 40s\n",
            "712:\tlearn: 0.6111875\ttotal: 26m 27s\tremaining: 10m 38s\n",
            "713:\tlearn: 0.6108896\ttotal: 26m 29s\tremaining: 10m 36s\n",
            "714:\tlearn: 0.6106064\ttotal: 26m 31s\tremaining: 10m 34s\n",
            "715:\tlearn: 0.6101651\ttotal: 26m 33s\tremaining: 10m 32s\n",
            "716:\tlearn: 0.6098592\ttotal: 26m 35s\tremaining: 10m 29s\n",
            "717:\tlearn: 0.6097043\ttotal: 26m 37s\tremaining: 10m 27s\n",
            "718:\tlearn: 0.6094720\ttotal: 26m 40s\tremaining: 10m 25s\n",
            "719:\tlearn: 0.6090877\ttotal: 26m 42s\tremaining: 10m 23s\n",
            "720:\tlearn: 0.6084393\ttotal: 26m 44s\tremaining: 10m 20s\n",
            "721:\tlearn: 0.6080099\ttotal: 26m 46s\tremaining: 10m 18s\n",
            "722:\tlearn: 0.6075677\ttotal: 26m 48s\tremaining: 10m 16s\n",
            "723:\tlearn: 0.6070907\ttotal: 26m 50s\tremaining: 10m 14s\n",
            "724:\tlearn: 0.6069304\ttotal: 26m 54s\tremaining: 10m 12s\n",
            "725:\tlearn: 0.6065769\ttotal: 26m 56s\tremaining: 10m 9s\n",
            "726:\tlearn: 0.6061571\ttotal: 26m 58s\tremaining: 10m 7s\n",
            "727:\tlearn: 0.6058005\ttotal: 27m\tremaining: 10m 5s\n",
            "728:\tlearn: 0.6051988\ttotal: 27m 2s\tremaining: 10m 3s\n",
            "729:\tlearn: 0.6048010\ttotal: 27m 4s\tremaining: 10m\n",
            "730:\tlearn: 0.6044322\ttotal: 27m 7s\tremaining: 9m 58s\n",
            "731:\tlearn: 0.6040548\ttotal: 27m 9s\tremaining: 9m 56s\n",
            "732:\tlearn: 0.6036798\ttotal: 27m 11s\tremaining: 9m 54s\n",
            "733:\tlearn: 0.6032547\ttotal: 27m 13s\tremaining: 9m 51s\n",
            "734:\tlearn: 0.6028553\ttotal: 27m 15s\tremaining: 9m 49s\n",
            "735:\tlearn: 0.6025591\ttotal: 27m 18s\tremaining: 9m 47s\n",
            "736:\tlearn: 0.6021293\ttotal: 27m 20s\tremaining: 9m 45s\n",
            "737:\tlearn: 0.6018264\ttotal: 27m 22s\tremaining: 9m 43s\n",
            "738:\tlearn: 0.6015505\ttotal: 27m 24s\tremaining: 9m 40s\n",
            "739:\tlearn: 0.6012443\ttotal: 27m 26s\tremaining: 9m 38s\n",
            "740:\tlearn: 0.6010837\ttotal: 27m 28s\tremaining: 9m 36s\n",
            "741:\tlearn: 0.6008673\ttotal: 27m 31s\tremaining: 9m 34s\n",
            "742:\tlearn: 0.6003498\ttotal: 27m 33s\tremaining: 9m 32s\n",
            "743:\tlearn: 0.6001249\ttotal: 27m 35s\tremaining: 9m 29s\n",
            "744:\tlearn: 0.5998615\ttotal: 27m 37s\tremaining: 9m 27s\n",
            "745:\tlearn: 0.5996681\ttotal: 27m 39s\tremaining: 9m 25s\n",
            "746:\tlearn: 0.5993920\ttotal: 27m 41s\tremaining: 9m 22s\n",
            "747:\tlearn: 0.5990277\ttotal: 27m 44s\tremaining: 9m 20s\n",
            "748:\tlearn: 0.5985989\ttotal: 27m 46s\tremaining: 9m 18s\n",
            "749:\tlearn: 0.5983619\ttotal: 27m 48s\tremaining: 9m 16s\n",
            "750:\tlearn: 0.5981378\ttotal: 27m 50s\tremaining: 9m 13s\n",
            "751:\tlearn: 0.5978959\ttotal: 27m 52s\tremaining: 9m 11s\n",
            "752:\tlearn: 0.5975441\ttotal: 27m 54s\tremaining: 9m 9s\n",
            "753:\tlearn: 0.5969354\ttotal: 27m 58s\tremaining: 9m 7s\n",
            "754:\tlearn: 0.5966878\ttotal: 28m\tremaining: 9m 5s\n",
            "755:\tlearn: 0.5964858\ttotal: 28m 2s\tremaining: 9m 2s\n",
            "756:\tlearn: 0.5961853\ttotal: 28m 3s\tremaining: 9m\n",
            "757:\tlearn: 0.5958971\ttotal: 28m 5s\tremaining: 8m 58s\n",
            "758:\tlearn: 0.5954134\ttotal: 28m 8s\tremaining: 8m 56s\n",
            "759:\tlearn: 0.5948372\ttotal: 28m 11s\tremaining: 8m 54s\n",
            "760:\tlearn: 0.5944737\ttotal: 28m 13s\tremaining: 8m 51s\n",
            "761:\tlearn: 0.5939693\ttotal: 28m 15s\tremaining: 8m 49s\n",
            "762:\tlearn: 0.5935916\ttotal: 28m 17s\tremaining: 8m 47s\n",
            "763:\tlearn: 0.5934646\ttotal: 28m 19s\tremaining: 8m 44s\n",
            "764:\tlearn: 0.5933093\ttotal: 28m 22s\tremaining: 8m 42s\n",
            "765:\tlearn: 0.5927749\ttotal: 28m 24s\tremaining: 8m 40s\n",
            "766:\tlearn: 0.5923871\ttotal: 28m 26s\tremaining: 8m 38s\n",
            "767:\tlearn: 0.5920405\ttotal: 28m 28s\tremaining: 8m 36s\n",
            "768:\tlearn: 0.5917205\ttotal: 28m 30s\tremaining: 8m 33s\n",
            "769:\tlearn: 0.5914590\ttotal: 28m 32s\tremaining: 8m 31s\n",
            "770:\tlearn: 0.5912932\ttotal: 28m 35s\tremaining: 8m 29s\n",
            "771:\tlearn: 0.5910049\ttotal: 28m 37s\tremaining: 8m 27s\n",
            "772:\tlearn: 0.5907649\ttotal: 28m 39s\tremaining: 8m 24s\n",
            "773:\tlearn: 0.5905098\ttotal: 28m 41s\tremaining: 8m 22s\n",
            "774:\tlearn: 0.5901469\ttotal: 28m 43s\tremaining: 8m 20s\n",
            "775:\tlearn: 0.5898525\ttotal: 28m 45s\tremaining: 8m 18s\n",
            "776:\tlearn: 0.5894268\ttotal: 28m 48s\tremaining: 8m 16s\n",
            "777:\tlearn: 0.5892386\ttotal: 28m 50s\tremaining: 8m 13s\n",
            "778:\tlearn: 0.5889032\ttotal: 28m 52s\tremaining: 8m 11s\n",
            "779:\tlearn: 0.5885820\ttotal: 28m 54s\tremaining: 8m 9s\n",
            "780:\tlearn: 0.5883269\ttotal: 28m 56s\tremaining: 8m 7s\n",
            "781:\tlearn: 0.5880761\ttotal: 28m 59s\tremaining: 8m 4s\n",
            "782:\tlearn: 0.5874334\ttotal: 29m 2s\tremaining: 8m 2s\n",
            "783:\tlearn: 0.5872223\ttotal: 29m 4s\tremaining: 8m\n",
            "784:\tlearn: 0.5866527\ttotal: 29m 6s\tremaining: 7m 58s\n",
            "785:\tlearn: 0.5863950\ttotal: 29m 8s\tremaining: 7m 55s\n",
            "786:\tlearn: 0.5862405\ttotal: 29m 10s\tremaining: 7m 53s\n",
            "787:\tlearn: 0.5858940\ttotal: 29m 12s\tremaining: 7m 51s\n",
            "788:\tlearn: 0.5855922\ttotal: 29m 15s\tremaining: 7m 49s\n",
            "789:\tlearn: 0.5854512\ttotal: 29m 17s\tremaining: 7m 47s\n",
            "790:\tlearn: 0.5851950\ttotal: 29m 19s\tremaining: 7m 44s\n",
            "791:\tlearn: 0.5849082\ttotal: 29m 21s\tremaining: 7m 42s\n",
            "792:\tlearn: 0.5845910\ttotal: 29m 23s\tremaining: 7m 40s\n",
            "793:\tlearn: 0.5843067\ttotal: 29m 26s\tremaining: 7m 38s\n",
            "794:\tlearn: 0.5840755\ttotal: 29m 28s\tremaining: 7m 36s\n",
            "795:\tlearn: 0.5836639\ttotal: 29m 30s\tremaining: 7m 33s\n",
            "796:\tlearn: 0.5833645\ttotal: 29m 32s\tremaining: 7m 31s\n",
            "797:\tlearn: 0.5831423\ttotal: 29m 34s\tremaining: 7m 29s\n",
            "798:\tlearn: 0.5828641\ttotal: 29m 36s\tremaining: 7m 26s\n",
            "799:\tlearn: 0.5827078\ttotal: 29m 39s\tremaining: 7m 24s\n",
            "800:\tlearn: 0.5822499\ttotal: 29m 41s\tremaining: 7m 22s\n",
            "801:\tlearn: 0.5818345\ttotal: 29m 43s\tremaining: 7m 20s\n",
            "802:\tlearn: 0.5814476\ttotal: 29m 45s\tremaining: 7m 18s\n",
            "803:\tlearn: 0.5811967\ttotal: 29m 47s\tremaining: 7m 15s\n",
            "804:\tlearn: 0.5808338\ttotal: 29m 49s\tremaining: 7m 13s\n",
            "805:\tlearn: 0.5806191\ttotal: 29m 52s\tremaining: 7m 11s\n",
            "806:\tlearn: 0.5804230\ttotal: 29m 54s\tremaining: 7m 9s\n",
            "807:\tlearn: 0.5801329\ttotal: 29m 56s\tremaining: 7m 6s\n",
            "808:\tlearn: 0.5798064\ttotal: 29m 58s\tremaining: 7m 4s\n",
            "809:\tlearn: 0.5792723\ttotal: 30m\tremaining: 7m 2s\n",
            "810:\tlearn: 0.5791095\ttotal: 30m 2s\tremaining: 7m\n",
            "811:\tlearn: 0.5789152\ttotal: 30m 5s\tremaining: 6m 58s\n",
            "812:\tlearn: 0.5787625\ttotal: 30m 7s\tremaining: 6m 55s\n",
            "813:\tlearn: 0.5781430\ttotal: 30m 9s\tremaining: 6m 53s\n",
            "814:\tlearn: 0.5777533\ttotal: 30m 11s\tremaining: 6m 51s\n",
            "815:\tlearn: 0.5771618\ttotal: 30m 13s\tremaining: 6m 48s\n",
            "816:\tlearn: 0.5768906\ttotal: 30m 16s\tremaining: 6m 46s\n",
            "817:\tlearn: 0.5764937\ttotal: 30m 19s\tremaining: 6m 44s\n",
            "818:\tlearn: 0.5762441\ttotal: 30m 21s\tremaining: 6m 42s\n",
            "819:\tlearn: 0.5759503\ttotal: 30m 23s\tremaining: 6m 40s\n",
            "820:\tlearn: 0.5755744\ttotal: 30m 25s\tremaining: 6m 37s\n",
            "821:\tlearn: 0.5754010\ttotal: 30m 26s\tremaining: 6m 35s\n",
            "822:\tlearn: 0.5751240\ttotal: 30m 29s\tremaining: 6m 33s\n",
            "823:\tlearn: 0.5749745\ttotal: 30m 31s\tremaining: 6m 31s\n",
            "824:\tlearn: 0.5748113\ttotal: 30m 33s\tremaining: 6m 29s\n",
            "825:\tlearn: 0.5744915\ttotal: 30m 35s\tremaining: 6m 26s\n",
            "826:\tlearn: 0.5740139\ttotal: 30m 37s\tremaining: 6m 24s\n",
            "827:\tlearn: 0.5736903\ttotal: 30m 39s\tremaining: 6m 22s\n",
            "828:\tlearn: 0.5735432\ttotal: 30m 43s\tremaining: 6m 20s\n",
            "829:\tlearn: 0.5733446\ttotal: 30m 45s\tremaining: 6m 17s\n",
            "830:\tlearn: 0.5731693\ttotal: 30m 47s\tremaining: 6m 15s\n",
            "831:\tlearn: 0.5730503\ttotal: 30m 49s\tremaining: 6m 13s\n",
            "832:\tlearn: 0.5728448\ttotal: 30m 51s\tremaining: 6m 11s\n",
            "833:\tlearn: 0.5724953\ttotal: 30m 53s\tremaining: 6m 8s\n",
            "834:\tlearn: 0.5723691\ttotal: 30m 56s\tremaining: 6m 6s\n",
            "835:\tlearn: 0.5720782\ttotal: 30m 58s\tremaining: 6m 4s\n",
            "836:\tlearn: 0.5718491\ttotal: 31m\tremaining: 6m 2s\n",
            "837:\tlearn: 0.5715613\ttotal: 31m 2s\tremaining: 6m\n",
            "838:\tlearn: 0.5713497\ttotal: 31m 4s\tremaining: 5m 57s\n",
            "839:\tlearn: 0.5709021\ttotal: 31m 6s\tremaining: 5m 55s\n",
            "840:\tlearn: 0.5705438\ttotal: 31m 9s\tremaining: 5m 53s\n",
            "841:\tlearn: 0.5701850\ttotal: 31m 11s\tremaining: 5m 51s\n",
            "842:\tlearn: 0.5698946\ttotal: 31m 13s\tremaining: 5m 48s\n",
            "843:\tlearn: 0.5696905\ttotal: 31m 15s\tremaining: 5m 46s\n",
            "844:\tlearn: 0.5694249\ttotal: 31m 17s\tremaining: 5m 44s\n",
            "845:\tlearn: 0.5692017\ttotal: 31m 20s\tremaining: 5m 42s\n",
            "846:\tlearn: 0.5688224\ttotal: 31m 22s\tremaining: 5m 40s\n",
            "847:\tlearn: 0.5685933\ttotal: 31m 24s\tremaining: 5m 37s\n",
            "848:\tlearn: 0.5682282\ttotal: 31m 26s\tremaining: 5m 35s\n",
            "849:\tlearn: 0.5679374\ttotal: 31m 28s\tremaining: 5m 33s\n",
            "850:\tlearn: 0.5673156\ttotal: 31m 30s\tremaining: 5m 31s\n",
            "851:\tlearn: 0.5672047\ttotal: 31m 33s\tremaining: 5m 28s\n",
            "852:\tlearn: 0.5669406\ttotal: 31m 35s\tremaining: 5m 26s\n",
            "853:\tlearn: 0.5665487\ttotal: 31m 37s\tremaining: 5m 24s\n",
            "854:\tlearn: 0.5663438\ttotal: 31m 39s\tremaining: 5m 22s\n",
            "855:\tlearn: 0.5656979\ttotal: 31m 41s\tremaining: 5m 19s\n",
            "856:\tlearn: 0.5654505\ttotal: 31m 43s\tremaining: 5m 17s\n",
            "857:\tlearn: 0.5651782\ttotal: 31m 46s\tremaining: 5m 15s\n",
            "858:\tlearn: 0.5648955\ttotal: 31m 48s\tremaining: 5m 13s\n",
            "859:\tlearn: 0.5647176\ttotal: 31m 50s\tremaining: 5m 11s\n",
            "860:\tlearn: 0.5645186\ttotal: 31m 52s\tremaining: 5m 8s\n",
            "861:\tlearn: 0.5640972\ttotal: 31m 54s\tremaining: 5m 6s\n",
            "862:\tlearn: 0.5638135\ttotal: 31m 57s\tremaining: 5m 4s\n",
            "863:\tlearn: 0.5635105\ttotal: 32m\tremaining: 5m 2s\n",
            "864:\tlearn: 0.5628994\ttotal: 32m 2s\tremaining: 4m 59s\n",
            "865:\tlearn: 0.5626448\ttotal: 32m 4s\tremaining: 4m 57s\n",
            "866:\tlearn: 0.5622890\ttotal: 32m 6s\tremaining: 4m 55s\n",
            "867:\tlearn: 0.5619926\ttotal: 32m 8s\tremaining: 4m 53s\n",
            "868:\tlearn: 0.5618361\ttotal: 32m 11s\tremaining: 4m 51s\n",
            "869:\tlearn: 0.5615548\ttotal: 32m 13s\tremaining: 4m 48s\n",
            "870:\tlearn: 0.5613681\ttotal: 32m 15s\tremaining: 4m 46s\n",
            "871:\tlearn: 0.5608954\ttotal: 32m 17s\tremaining: 4m 44s\n",
            "872:\tlearn: 0.5607275\ttotal: 32m 19s\tremaining: 4m 42s\n",
            "873:\tlearn: 0.5604980\ttotal: 32m 21s\tremaining: 4m 39s\n",
            "874:\tlearn: 0.5603263\ttotal: 32m 24s\tremaining: 4m 37s\n",
            "875:\tlearn: 0.5600700\ttotal: 32m 26s\tremaining: 4m 35s\n",
            "876:\tlearn: 0.5597550\ttotal: 32m 28s\tremaining: 4m 33s\n",
            "877:\tlearn: 0.5595703\ttotal: 32m 30s\tremaining: 4m 31s\n",
            "878:\tlearn: 0.5593790\ttotal: 32m 32s\tremaining: 4m 28s\n",
            "879:\tlearn: 0.5590511\ttotal: 32m 34s\tremaining: 4m 26s\n",
            "880:\tlearn: 0.5588031\ttotal: 32m 37s\tremaining: 4m 24s\n",
            "881:\tlearn: 0.5585847\ttotal: 32m 39s\tremaining: 4m 22s\n",
            "882:\tlearn: 0.5583956\ttotal: 32m 41s\tremaining: 4m 19s\n",
            "883:\tlearn: 0.5582171\ttotal: 32m 43s\tremaining: 4m 17s\n",
            "884:\tlearn: 0.5579711\ttotal: 32m 45s\tremaining: 4m 15s\n",
            "885:\tlearn: 0.5574035\ttotal: 32m 47s\tremaining: 4m 13s\n",
            "886:\tlearn: 0.5569717\ttotal: 32m 50s\tremaining: 4m 11s\n",
            "887:\tlearn: 0.5566123\ttotal: 32m 52s\tremaining: 4m 8s\n",
            "888:\tlearn: 0.5565018\ttotal: 32m 54s\tremaining: 4m 6s\n",
            "889:\tlearn: 0.5561994\ttotal: 32m 56s\tremaining: 4m 4s\n",
            "890:\tlearn: 0.5558946\ttotal: 32m 58s\tremaining: 4m 2s\n",
            "891:\tlearn: 0.5556189\ttotal: 33m\tremaining: 3m 59s\n",
            "892:\tlearn: 0.5553925\ttotal: 33m 3s\tremaining: 3m 57s\n",
            "893:\tlearn: 0.5552926\ttotal: 33m 5s\tremaining: 3m 55s\n",
            "894:\tlearn: 0.5550983\ttotal: 33m 7s\tremaining: 3m 53s\n",
            "895:\tlearn: 0.5548974\ttotal: 33m 9s\tremaining: 3m 50s\n",
            "896:\tlearn: 0.5545697\ttotal: 33m 11s\tremaining: 3m 48s\n",
            "897:\tlearn: 0.5541182\ttotal: 33m 13s\tremaining: 3m 46s\n",
            "898:\tlearn: 0.5540285\ttotal: 33m 16s\tremaining: 3m 44s\n",
            "899:\tlearn: 0.5538770\ttotal: 33m 18s\tremaining: 3m 42s\n",
            "900:\tlearn: 0.5536723\ttotal: 33m 20s\tremaining: 3m 39s\n",
            "901:\tlearn: 0.5534512\ttotal: 33m 22s\tremaining: 3m 37s\n",
            "902:\tlearn: 0.5530676\ttotal: 33m 24s\tremaining: 3m 35s\n",
            "903:\tlearn: 0.5526944\ttotal: 33m 26s\tremaining: 3m 33s\n",
            "904:\tlearn: 0.5523208\ttotal: 33m 29s\tremaining: 3m 30s\n",
            "905:\tlearn: 0.5522503\ttotal: 33m 31s\tremaining: 3m 28s\n",
            "906:\tlearn: 0.5520681\ttotal: 33m 33s\tremaining: 3m 26s\n",
            "907:\tlearn: 0.5517705\ttotal: 33m 35s\tremaining: 3m 24s\n",
            "908:\tlearn: 0.5514240\ttotal: 33m 37s\tremaining: 3m 21s\n",
            "909:\tlearn: 0.5511061\ttotal: 33m 40s\tremaining: 3m 19s\n",
            "910:\tlearn: 0.5508812\ttotal: 33m 42s\tremaining: 3m 17s\n",
            "911:\tlearn: 0.5506326\ttotal: 33m 44s\tremaining: 3m 15s\n",
            "912:\tlearn: 0.5503417\ttotal: 33m 46s\tremaining: 3m 13s\n",
            "913:\tlearn: 0.5501893\ttotal: 33m 48s\tremaining: 3m 10s\n",
            "914:\tlearn: 0.5499089\ttotal: 33m 50s\tremaining: 3m 8s\n",
            "915:\tlearn: 0.5498450\ttotal: 33m 53s\tremaining: 3m 6s\n",
            "916:\tlearn: 0.5495593\ttotal: 33m 55s\tremaining: 3m 4s\n",
            "917:\tlearn: 0.5491585\ttotal: 33m 57s\tremaining: 3m 1s\n",
            "918:\tlearn: 0.5488247\ttotal: 33m 59s\tremaining: 2m 59s\n",
            "919:\tlearn: 0.5484865\ttotal: 34m 1s\tremaining: 2m 57s\n",
            "920:\tlearn: 0.5481397\ttotal: 34m 3s\tremaining: 2m 55s\n",
            "921:\tlearn: 0.5475882\ttotal: 34m 6s\tremaining: 2m 53s\n",
            "922:\tlearn: 0.5473622\ttotal: 34m 8s\tremaining: 2m 50s\n",
            "923:\tlearn: 0.5471462\ttotal: 34m 10s\tremaining: 2m 48s\n",
            "924:\tlearn: 0.5467186\ttotal: 34m 12s\tremaining: 2m 46s\n",
            "925:\tlearn: 0.5463853\ttotal: 34m 14s\tremaining: 2m 44s\n",
            "926:\tlearn: 0.5462818\ttotal: 34m 16s\tremaining: 2m 41s\n",
            "927:\tlearn: 0.5460982\ttotal: 34m 19s\tremaining: 2m 39s\n",
            "928:\tlearn: 0.5457892\ttotal: 34m 21s\tremaining: 2m 37s\n",
            "929:\tlearn: 0.5453240\ttotal: 34m 23s\tremaining: 2m 35s\n",
            "930:\tlearn: 0.5449904\ttotal: 34m 25s\tremaining: 2m 33s\n",
            "931:\tlearn: 0.5445122\ttotal: 34m 27s\tremaining: 2m 30s\n",
            "932:\tlearn: 0.5441372\ttotal: 34m 29s\tremaining: 2m 28s\n",
            "933:\tlearn: 0.5439666\ttotal: 34m 32s\tremaining: 2m 26s\n",
            "934:\tlearn: 0.5436797\ttotal: 34m 34s\tremaining: 2m 24s\n",
            "935:\tlearn: 0.5434540\ttotal: 34m 36s\tremaining: 2m 21s\n",
            "936:\tlearn: 0.5431358\ttotal: 34m 38s\tremaining: 2m 19s\n",
            "937:\tlearn: 0.5429477\ttotal: 34m 40s\tremaining: 2m 17s\n",
            "938:\tlearn: 0.5426906\ttotal: 34m 42s\tremaining: 2m 15s\n",
            "939:\tlearn: 0.5424635\ttotal: 34m 45s\tremaining: 2m 13s\n",
            "940:\tlearn: 0.5423643\ttotal: 34m 47s\tremaining: 2m 10s\n",
            "941:\tlearn: 0.5421234\ttotal: 34m 49s\tremaining: 2m 8s\n",
            "942:\tlearn: 0.5418822\ttotal: 34m 51s\tremaining: 2m 6s\n",
            "943:\tlearn: 0.5416624\ttotal: 34m 53s\tremaining: 2m 4s\n",
            "944:\tlearn: 0.5412586\ttotal: 34m 55s\tremaining: 2m 1s\n",
            "945:\tlearn: 0.5408547\ttotal: 34m 58s\tremaining: 1m 59s\n",
            "946:\tlearn: 0.5404395\ttotal: 35m\tremaining: 1m 57s\n",
            "947:\tlearn: 0.5398383\ttotal: 35m 2s\tremaining: 1m 55s\n",
            "948:\tlearn: 0.5396942\ttotal: 35m 4s\tremaining: 1m 53s\n",
            "949:\tlearn: 0.5394259\ttotal: 35m 6s\tremaining: 1m 50s\n",
            "950:\tlearn: 0.5389704\ttotal: 35m 9s\tremaining: 1m 48s\n",
            "951:\tlearn: 0.5388482\ttotal: 35m 11s\tremaining: 1m 46s\n",
            "952:\tlearn: 0.5386517\ttotal: 35m 13s\tremaining: 1m 44s\n",
            "953:\tlearn: 0.5383568\ttotal: 35m 15s\tremaining: 1m 41s\n",
            "954:\tlearn: 0.5381569\ttotal: 35m 17s\tremaining: 1m 39s\n",
            "955:\tlearn: 0.5378403\ttotal: 35m 19s\tremaining: 1m 37s\n",
            "956:\tlearn: 0.5375928\ttotal: 35m 22s\tremaining: 1m 35s\n",
            "957:\tlearn: 0.5374926\ttotal: 35m 24s\tremaining: 1m 33s\n",
            "958:\tlearn: 0.5372567\ttotal: 35m 26s\tremaining: 1m 30s\n",
            "959:\tlearn: 0.5370043\ttotal: 35m 28s\tremaining: 1m 28s\n",
            "960:\tlearn: 0.5367168\ttotal: 35m 30s\tremaining: 1m 26s\n",
            "961:\tlearn: 0.5366052\ttotal: 35m 32s\tremaining: 1m 24s\n",
            "962:\tlearn: 0.5361653\ttotal: 35m 35s\tremaining: 1m 22s\n",
            "963:\tlearn: 0.5357556\ttotal: 35m 37s\tremaining: 1m 19s\n",
            "964:\tlearn: 0.5354500\ttotal: 35m 39s\tremaining: 1m 17s\n",
            "965:\tlearn: 0.5351831\ttotal: 35m 41s\tremaining: 1m 15s\n",
            "966:\tlearn: 0.5349787\ttotal: 35m 43s\tremaining: 1m 13s\n",
            "967:\tlearn: 0.5348225\ttotal: 35m 45s\tremaining: 1m 10s\n",
            "968:\tlearn: 0.5343800\ttotal: 35m 48s\tremaining: 1m 8s\n",
            "969:\tlearn: 0.5339376\ttotal: 35m 50s\tremaining: 1m 6s\n",
            "970:\tlearn: 0.5337362\ttotal: 35m 52s\tremaining: 1m 4s\n",
            "971:\tlearn: 0.5334257\ttotal: 35m 54s\tremaining: 1m 2s\n",
            "972:\tlearn: 0.5332698\ttotal: 35m 56s\tremaining: 59.8s\n",
            "973:\tlearn: 0.5329808\ttotal: 35m 58s\tremaining: 57.6s\n",
            "974:\tlearn: 0.5325325\ttotal: 36m 1s\tremaining: 55.4s\n",
            "975:\tlearn: 0.5324323\ttotal: 36m 3s\tremaining: 53.2s\n",
            "976:\tlearn: 0.5319472\ttotal: 36m 5s\tremaining: 51s\n",
            "977:\tlearn: 0.5316604\ttotal: 36m 6s\tremaining: 48.7s\n",
            "978:\tlearn: 0.5313767\ttotal: 36m 8s\tremaining: 46.5s\n",
            "979:\tlearn: 0.5312339\ttotal: 36m 11s\tremaining: 44.3s\n",
            "980:\tlearn: 0.5307876\ttotal: 36m 13s\tremaining: 42.1s\n",
            "981:\tlearn: 0.5303634\ttotal: 36m 15s\tremaining: 39.9s\n",
            "982:\tlearn: 0.5301072\ttotal: 36m 17s\tremaining: 37.7s\n",
            "983:\tlearn: 0.5297258\ttotal: 36m 19s\tremaining: 35.4s\n",
            "984:\tlearn: 0.5293669\ttotal: 36m 21s\tremaining: 33.2s\n",
            "985:\tlearn: 0.5291343\ttotal: 36m 24s\tremaining: 31s\n",
            "986:\tlearn: 0.5289433\ttotal: 36m 26s\tremaining: 28.8s\n",
            "987:\tlearn: 0.5287398\ttotal: 36m 28s\tremaining: 26.6s\n",
            "988:\tlearn: 0.5284661\ttotal: 36m 30s\tremaining: 24.4s\n",
            "989:\tlearn: 0.5283197\ttotal: 36m 32s\tremaining: 22.1s\n",
            "990:\tlearn: 0.5280452\ttotal: 36m 34s\tremaining: 19.9s\n",
            "991:\tlearn: 0.5276915\ttotal: 36m 36s\tremaining: 17.7s\n",
            "992:\tlearn: 0.5275802\ttotal: 36m 39s\tremaining: 15.5s\n",
            "993:\tlearn: 0.5270801\ttotal: 36m 41s\tremaining: 13.3s\n",
            "994:\tlearn: 0.5269779\ttotal: 36m 43s\tremaining: 11.1s\n",
            "995:\tlearn: 0.5265856\ttotal: 36m 45s\tremaining: 8.86s\n",
            "996:\tlearn: 0.5262263\ttotal: 36m 47s\tremaining: 6.64s\n",
            "997:\tlearn: 0.5259710\ttotal: 36m 50s\tremaining: 4.43s\n",
            "998:\tlearn: 0.5258456\ttotal: 36m 52s\tremaining: 2.21s\n",
            "999:\tlearn: 0.5257133\ttotal: 36m 54s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7fdaf4c10f40>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf_pred = cb_clf.predict(test_f)"
      ],
      "metadata": {
        "id": "SgVwxkbM2U9w"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_clf = accuracy_score(test_f_labels, clf_pred)\n",
        "print('Accuracy: {:.2f}'.format(accuracy_clf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wZBPI3r3DYq",
        "outputId": "be2f2a6d-cebe-4d7d-afaa-fe7ae9ce02d9"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.69\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}